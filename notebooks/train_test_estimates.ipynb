{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error, mean_absolute_percentage_error, explained_variance_score, max_error, accuracy_score \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np \n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "# from catboost import CatBoostRegressor # CatBoost убран\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для расчета точности определения знака\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "# Загрузка данных\n",
    "# Убедитесь, что путь к файлу указан верно\n",
    "try:\n",
    "    lkoh_df = pd.read_csv('../data/features_final/LKOH_final.csv')\n",
    "    print(\"Данные для LKOH загружены успешно.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл LKOH_final.csv не найден. Проверьте путь к файлу.\")\n",
    "    # Можно добавить код для загрузки других тикеров или обработки ошибки\n",
    "\n",
    "# Определение целевых переменных\n",
    "targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Определение признаков оценки новостей для LKOH\n",
    "# Для других тикеров 'LKOH' нужно будет заменить на соответствующий тикер\n",
    "ticker_prefix = 'LKOH' # Это нужно будет менять для других тикеров\n",
    "\n",
    "news_features = [\n",
    "    f'{ticker_prefix}_news_score', f'{ticker_prefix}_news_score_roll_avg_5', \n",
    "    f'{ticker_prefix}_news_score_roll_avg_15', f'{ticker_prefix}_news_score_roll_avg_30',\n",
    "    'WeightedIndices_news_score', 'WeightedIndices_news_score_roll_avg_5', \n",
    "    'WeightedIndices_news_score_roll_avg_15', 'WeightedIndices_news_score_roll_avg_30'\n",
    "]\n",
    "\n",
    "# Определение признаков оценки блогов для LKOH\n",
    "blog_features = [\n",
    "    f'{ticker_prefix}_blog_score', f'{ticker_prefix}_blog_score_roll_avg_5', \n",
    "    f'{ticker_prefix}_blog_score_roll_avg_15', f'{ticker_prefix}_blog_score_roll_avg_30',\n",
    "    'WeightedIndices_blog_score', 'WeightedIndices_blog_score_roll_avg_5', \n",
    "    'WeightedIndices_blog_score_roll_avg_15', 'WeightedIndices_blog_score_roll_avg_30'\n",
    "]\n",
    "\n",
    "# Определение базовых признаков \n",
    "# (все, кроме целевых, новостных и блоговых, а также исключаем 'Date' и 'Ticker' и другие специфичные для таргетов колонки)\n",
    "# Сначала получим все колонки\n",
    "all_columns = lkoh_df.columns.tolist()\n",
    "\n",
    "# Колонки, которые точно не являются признаками\n",
    "excluded_columns = targets + news_features + blog_features + ['Date', 'Ticker']\n",
    "\n",
    "# Дополнительно убедимся, что не включаем колонки, которые могут содержать информацию о будущем или являются вариациями таргетов\n",
    "# Например, если есть колонки типа 'price_change_next_N_days' и т.п., их тоже надо исключить.\n",
    "# В данном случае, предполагаем, что остальные колонки - это базовые признаки.\n",
    "base_features = [col for col in all_columns if col not in excluded_columns]\n",
    "\n",
    "# Удалим признаки, которые могут содержать NaN из-за rolling averages на начальных этапах, если они есть только в начале\n",
    "# Это специфично для данных и требует их анализа. Пока оставим как есть.\n",
    "# lkoh_df.dropna(subset=base_features + news_features + blog_features, inplace=True) # Раскомментировать и адаптировать при необходимости\n",
    "\n",
    "\n",
    "print(f\"Количество базовых признаков: {len(base_features)}\")\n",
    "if len(base_features) > 0:\n",
    "    print(f\"Пример базовых признаков: {base_features[:5]}...\")\n",
    "else:\n",
    "    print(\"Базовые признаки не определены. Проверьте логику исключения колонок.\")\n",
    "    \n",
    "print(f\"Новостные признаки: {news_features}\")\n",
    "print(f\"Блоговые признаки: {blog_features}\")\n",
    "\n",
    "# Проверка наличия всех признаков в DataFrame\n",
    "missing_news_features = [f for f in news_features if f not in lkoh_df.columns]\n",
    "missing_blog_features = [f for f in blog_features if f not in lkoh_df.columns]\n",
    "missing_base_features = [f for f in base_features if f not in lkoh_df.columns] # Хотя это должно быть пусто по определению\n",
    "\n",
    "if missing_news_features:\n",
    "    print(f\"ВНИМАНИЕ: Следующие новостные признаки отсутствуют в LKOH_final.csv: {missing_news_features}\")\n",
    "if missing_blog_features:\n",
    "    print(f\"ВНИМАНИЕ: Следующие блоговые признаки отсутствуют в LKOH_final.csv: {missing_blog_features}\")\n",
    "\n",
    "# Определим наборы признаков для экспериментов:\n",
    "# 1. Только базовые признаки\n",
    "features_set_1 = base_features\n",
    "# 2. Базовые + новостные\n",
    "features_set_2 = base_features + [f for f in news_features if f in lkoh_df.columns] # Используем только существующие\n",
    "# 3. Базовые + новостные + блоговые\n",
    "features_set_3 = base_features + [f for f in news_features if f in lkoh_df.columns] + [f for f in blog_features if f in lkoh_df.columns] # Используем только существующие\n",
    "\n",
    "print(f\"\\\\nКоличество признаков в наборе 1 (базовые): {len(features_set_1)}\")\n",
    "print(f\"Количество признаков в наборе 2 (базовые + новости): {len(features_set_2)}\")\n",
    "print(f\"Количество признаков в наборе 3 (базовые + новости + блоги): {len(features_set_3)}\")\n",
    "\n",
    "# Выведем первые несколько строк датафрейма для ознакомления\n",
    "print(\"\\\\nПервые 5 строк DataFrame LKOH:\")\n",
    "print(lkoh_df.head())\n",
    "\n",
    "# Проверим типы данных и наличие пропусков в целевых переменных\n",
    "print(\"\\\\nИнформация о DataFrame LKOH:\")\n",
    "lkoh_df.info()\n",
    "\n",
    "print(\"\\\\nПроверка на пропуски в целевых переменных LKOH:\")\n",
    "print(lkoh_df[targets].isnull().sum())\n",
    "\n",
    "# Удаление строк с NaN в целевых переменных, если они есть\n",
    "# lkoh_df.dropna(subset=targets, inplace=True)\n",
    "# print(\"\\\\nРазмер DataFrame после удаления строк с NaN в таргетах:\", lkoh_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_accuracy должна быть определена глобально, обычно в первой ячейке.\n",
    "# Убедитесь, что ячейка с ее определением выполнена.\n",
    "# def sign_accuracy(y_true, y_pred):\n",
    "#    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "def train_and_evaluate_models(df, features, target_col, ticker_name, test_size=0.2, n_iter_search=10, cv_search=3):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модели регрессии (LightGBM, XGBoost) \n",
    "    с подбором гиперпараметров через RandomizedSearchCV и расширенным набором метрик.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    current_features = [f for f in features if f in df.columns]\n",
    "    if not current_features:\n",
    "        print(f\"[{ticker_name} - {target_col}] Ни один из указанных признаков не найден. Пропуск.\")\n",
    "        return {}\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"[{ticker_name} - {target_col}] Целевая переменная '{target_col}' не найдена. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X = df[current_features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    combined_df = pd.concat([X, y], axis=1)\n",
    "    combined_df.dropna(inplace=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(f\"[{ticker_name} - {target_col}] DataFrame пуст после удаления NaN. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X = combined_df[current_features]\n",
    "    y = combined_df[target_col]\n",
    "\n",
    "    if X.empty or len(y) < (1/test_size) + cv_search: \n",
    "        print(f\"[{ticker_name} - {target_col}] Недостаточно данных для обучения/тестирования/CV ({X.shape}, y: {y.shape}). Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    if X_train.empty or X_test.empty or len(X_train) < cv_search or len(y_train) < cv_search:\n",
    "        print(f\"[{ticker_name} - {target_col}] Тренировочная/тестовая выборка или данных для CV недостаточно. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    base_lgbm = lgb.LGBMRegressor(random_state=42, verbosity=-1)\n",
    "    base_xgb = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "    param_dist_lgbm = {\n",
    "        'n_estimators': [300, 500, 800],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [20, 31, 40, 50],\n",
    "        'max_depth': [-1, 5, 10, 15],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    param_dist_xgb = {\n",
    "        'n_estimators': [300, 500, 800],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    models_config = {\n",
    "        'LGBM': (base_lgbm, param_dist_lgbm),\n",
    "        'XGBoost': (base_xgb, param_dist_xgb),\n",
    "    }\n",
    "\n",
    "    # Обновленный словарь scorers (удалена 'Accuracy')\n",
    "    scorers = {\n",
    "        'R2': r2_score,\n",
    "        'MAE': mean_absolute_error,\n",
    "        'MSE': mean_squared_error,\n",
    "        'MedAE': median_absolute_error, \n",
    "        'MAPE': mean_absolute_percentage_error, \n",
    "        'ExplainedVariance': explained_variance_score, \n",
    "        'MaxError': max_error, \n",
    "        'Sign Accuracy': sign_accuracy \n",
    "        # 'Accuracy': accuracy_score # Удалено, т.к. это для классификации\n",
    "    }\n",
    "\n",
    "    for model_name, (model_base, params) in models_config.items():\n",
    "        print(f\"  Подбор параметров для {model_name}, таргет {target_col}...\")\n",
    "        \n",
    "        current_cv = min(cv_search, len(X_train) // 2) \n",
    "        if len(X_train) < 2 or current_cv < 2: \n",
    "             print(f\"    Недостаточно данных в X_train ({len(X_train)}) для кросс-валидации с {current_cv} фолдами. Пропуск {model_name}.\")\n",
    "             # Заполняем NaN для всех метрик, включая RMSE и best_params\n",
    "             results[model_name] = {metric: np.nan for metric in scorers.keys()}\n",
    "             results[model_name]['RMSE'] = np.nan\n",
    "             results[model_name]['best_params'] = {}\n",
    "             continue\n",
    "\n",
    "        try:\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=model_base, \n",
    "                param_distributions=params, \n",
    "                n_iter=n_iter_search, \n",
    "                cv=current_cv, \n",
    "                scoring='r2', \n",
    "                random_state=42,\n",
    "                n_jobs=-1 \n",
    "            )\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            best_model = search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            model_metrics = {}\n",
    "            for metric_name, scorer_func in scorers.items():\n",
    "                if metric_name == 'MAPE' and np.any(y_test == 0):\n",
    "                    pass \n",
    "                model_metrics[metric_name] = scorer_func(y_test, y_pred)\n",
    "            \n",
    "            # Проверяем, есть ли MSE перед вычислением RMSE\n",
    "            if 'MSE' in model_metrics and not np.isnan(model_metrics['MSE']):\n",
    "                model_metrics['RMSE'] = np.sqrt(model_metrics['MSE'])\n",
    "            else:\n",
    "                model_metrics['RMSE'] = np.nan # Если MSE нет или NaN, RMSE тоже NaN\n",
    "                \n",
    "            model_metrics['best_params'] = search.best_params_\n",
    "            results[model_name] = model_metrics\n",
    "            print(f\"    {model_name} (tuned) R2: {model_metrics.get('R2', float('nan')):.4f}, Sign Acc: {model_metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при подборе/обучении модели {model_name} для {target_col} тикера {ticker_name}: {e}\")\n",
    "            # Заполняем NaN для всех метрик, включая RMSE и best_params, в случае ошибки\n",
    "            results[model_name] = {metric: np.nan for metric in scorers.keys()}\n",
    "            results[model_name]['RMSE'] = np.nan\n",
    "            results[model_name]['best_params'] = {}\n",
    "            \n",
    "    return results\n",
    "\n",
    "print(\"Функция train_and_evaluate_models обновлена: удалена метрика 'Accuracy' и улучшена обработка RMSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_process = ['LKOH', 'SBER', 'GAZP'] # Добавьте сюда другие тикеры при необходимости\n",
    "data_path_template = '../data/features_final/{}_final.csv'\n",
    "\n",
    "all_experiment_results = []\n",
    "\n",
    "# Глобально определенные целевые переменные (из предыдущей ячейки)\n",
    "# targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Параметры для RandomizedSearchCV (можно настроить)\n",
    "n_iterations_rscv = 30 # Уменьшено для скорости, можно увеличить для более тщательного поиска\n",
    "cv_folds_rscv = 3      # Количество фолдов\n",
    "\n",
    "for ticker in tickers_to_process:\n",
    "    print(f\"\\nProcessing Ticker: {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # Динамическое определение новостных и блоговых признаков\n",
    "    current_news_features = [\n",
    "        f'{ticker}_news_score', f'{ticker}_news_score_roll_avg_5', \n",
    "        f'{ticker}_news_score_roll_avg_15', f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score', 'WeightedIndices_news_score_roll_avg_5', \n",
    "        'WeightedIndices_news_score_roll_avg_15', 'WeightedIndices_news_score_roll_avg_30'\n",
    "    ]\n",
    "    current_blog_features = [\n",
    "        f'{ticker}_blog_score', f'{ticker}_blog_score_roll_avg_5', \n",
    "        f'{ticker}_blog_score_roll_avg_15', f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score', 'WeightedIndices_blog_score_roll_avg_5', \n",
    "        'WeightedIndices_blog_score_roll_avg_15', 'WeightedIndices_blog_score_roll_avg_30'\n",
    "    ]\n",
    "\n",
    "    # Отфильтруем только существующие в данном датасете признаки\n",
    "    actual_news_features = [f for f in current_news_features if f in df_ticker.columns]\n",
    "    actual_blog_features = [f for f in current_blog_features if f in df_ticker.columns]\n",
    "\n",
    "    # Определение базовых признаков\n",
    "    all_columns = df_ticker.columns.tolist()\n",
    "    excluded_for_base = targets + actual_news_features + actual_blog_features\n",
    "    # Добавим стандартные колонки, не являющиеся признаками (учитываем разные написания Date/date)\n",
    "    potential_non_features = ['DATE', 'date', 'Ticker', 'SECID', 'TRADEDATE', 'tradetimestamp'] \n",
    "    for col_name in potential_non_features:\n",
    "        if col_name in all_columns and col_name not in excluded_for_base:\n",
    "            excluded_for_base.append(col_name)\n",
    "    \n",
    "    current_base_features = [col for col in all_columns if col not in excluded_for_base]\n",
    "    \n",
    "    if not current_base_features:\n",
    "        print(f\"Не найдено базовых признаков для {ticker} после исключения. Проверьте логику! Пропуск тикера.\")\n",
    "        continue\n",
    "    print(f\"Для {ticker}: Найдено {len(current_base_features)} базовых признаков.\")\n",
    "\n",
    "    # Определяем наборы признаков для экспериментов\n",
    "    feature_sets_defs = {\n",
    "        \"BaseFeatures\": current_base_features,\n",
    "        \"BasePlusNews\": current_base_features + actual_news_features,\n",
    "        \"BasePlusNewsBlogs\": current_base_features + actual_news_features + actual_blog_features\n",
    "    }\n",
    "\n",
    "    for target_col in targets:\n",
    "        print(f\"\\n  Processing Target: {target_col} for Ticker: {ticker}\")\n",
    "        if target_col not in df_ticker.columns:\n",
    "            print(f\"    Целевая переменная {target_col} отсутствует в данных для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "            \n",
    "        # Проверка на наличие достаточного количества не-NaN значений в таргете\n",
    "        if df_ticker[target_col].isnull().all() or df_ticker[target_col].nunique() < 2:\n",
    "            print(f\"    Целевая переменная {target_col} для {ticker} содержит все NaN или только одно уникальное значение. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs.items():\n",
    "            print(f\"\\n    Training with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            # Убедимся, что в fs_features нет дубликатов (на случай если base уже содержал news/blog из-за ошибки в именовании)\n",
    "            unique_fs_features = sorted(list(set(fs_features)))\n",
    "            if len(unique_fs_features) == 0:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            # Создаем копию DataFrame для каждой итерации, чтобы избежать модификации оригинала при удалении NaNs\n",
    "            # и для обработки NaNs специфично для текущего набора признаков и таргета\n",
    "            df_loop_copy = df_ticker.copy()\n",
    "\n",
    "            model_metrics_results = train_and_evaluate_models(\n",
    "                df_loop_copy, \n",
    "                unique_fs_features, \n",
    "                target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': target_col,\n",
    "                    'FeatureSet': fs_name,\n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics) # Добавляем все метрики и best_params\n",
    "                all_experiment_results.append(result_row)\n",
    "                \n",
    "                if metrics and 'R2' in metrics : # Проверяем что метрики не пустые\n",
    "                    print(f\"      {model_name} for {fs_name} -> R2: {metrics.get('R2', float('nan')):.4f}, SignAcc: {metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "# Преобразование результатов в DataFrame\n",
    "results_df = pd.DataFrame(all_experiment_results)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты завершены!\")\n",
    "if not results_df.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    # Сохранение результатов в CSV (опционально)\n",
    "    # results_df.to_csv('market_prediction_experiment_results.csv', index=False)\n",
    "    # print(\"\\nРезультаты сохранены в market_prediction_experiment_results.csv\")\n",
    "else:\n",
    "    print(\"DataFrame с результатами пуст. Проверьте логи и возможные ошибки.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkoh_df = pd.read_csv('../data/features_final/LKOH_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkoh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл исследования (с обновленными наборами признаков)\n",
    "\n",
    "tickers_to_process = ['LKOH', 'SBER', 'GAZP']\n",
    "data_path_template = '../data/features_final/{}_final.csv'\n",
    "\n",
    "all_experiment_results_V2 = [] # Новая переменная для результатов с новым набором признаков\n",
    "\n",
    "# Определяем целевые переменные (должны быть доступны из предыдущих ячеек)\n",
    "# targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Параметры для RandomizedSearchCV\n",
    "n_iterations_rscv = 50\n",
    "cv_folds_rscv = 3      \n",
    "\n",
    "# Новый, сокращенный список \"самых важных\" базовых признаков\n",
    "selected_base_features_template = [\n",
    "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', \n",
    "    'RSI', 'MACD_Hist', 'Bear_Power', 'ATR', 'EMA_10', 'EMA_50', 'EMA_200', 'RTSI', 'EMV', 'ADX',\n",
    "    'MOEXCN', 'MOEXIT', 'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM', 'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH',\n",
    "    'Revenue_y', 'NetProfit_y', 'ROE_y', 'Assets_q', 'NetProfit_q', 'PB_q',\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'USD_RUB',\n",
    "    'PE_y', 'PB_y'\n",
    "]\n",
    "\n",
    "for ticker in tickers_to_process:\n",
    "    print(f\"\\nProcessing Ticker (V2 Features): {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # 1. Определение актуальных базовых признаков из нашего выбранного списка\n",
    "    actual_selected_base_features = [f for f in selected_base_features_template if f in df_ticker.columns]\n",
    "    if not actual_selected_base_features:\n",
    "        print(f\"Ни один из выбранных базовых признаков не найден для {ticker}. Пропуск тикера.\")\n",
    "        continue\n",
    "    print(f\"Для {ticker} (V2): Используется {len(actual_selected_base_features)} выбранных базовых признаков.\")\n",
    "\n",
    "    # 2. Определение новостных и блоговых признаков (только для тикера, без WeightedIndices)\n",
    "    current_news_features_specific = [\n",
    "        f'{ticker}_news_score', \n",
    "        f'{ticker}_news_score_roll_avg_5',\n",
    "        f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score'\n",
    "    ]\n",
    "    current_blog_features_specific = [\n",
    "        f'{ticker}_blog_score',\n",
    "        f'{ticker}_blog_score_roll_avg_5',\n",
    "        f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score'\n",
    "    ]\n",
    "    \n",
    "    # Отфильтруем только существующие в данном датасете специфичные признаки\n",
    "    actual_news_features_specific = [f for f in current_news_features_specific if f in df_ticker.columns]\n",
    "    actual_blog_features_specific = [f for f in current_blog_features_specific if f in df_ticker.columns]\n",
    "\n",
    "    # Определяем наборы признаков для экспериментов (V2)\n",
    "    feature_sets_defs_V2 = {\n",
    "        \"BaseFeatures_V2\": actual_selected_base_features,\n",
    "        \"BasePlusNews_V2\": actual_selected_base_features + actual_news_features_specific,\n",
    "        \"BasePlusNewsBlogs_V2\": actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific\n",
    "    }\n",
    "\n",
    "    for target_col in targets:\n",
    "        print(f\"\\n  Processing Target: {target_col} for Ticker: {ticker} (V2 Features)\")\n",
    "        if target_col not in df_ticker.columns:\n",
    "            print(f\"    Целевая переменная {target_col} отсутствует в данных для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "        if df_ticker[target_col].isnull().all() or df_ticker[target_col].nunique() < 2:\n",
    "            print(f\"    Целевая переменная {target_col} для {ticker} содержит все NaN или одно уникальное значение. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs_V2.items():\n",
    "            print(f\"\\n    Training with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            unique_fs_features = sorted(list(set(fs_features))) # Удаляем дубликаты, если вдруг появятся\n",
    "            if not unique_fs_features:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            df_loop_copy = df_ticker.copy()\n",
    "            model_metrics_results = train_and_evaluate_models(\n",
    "                df_loop_copy, \n",
    "                unique_fs_features, \n",
    "                target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': target_col,\n",
    "                    'FeatureSet': fs_name, # Используем новые имена наборов признаков\n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics)\n",
    "                all_experiment_results_V2.append(result_row)\n",
    "                \n",
    "                if metrics and 'R2' in metrics :\n",
    "                    print(f\"      {model_name} for {fs_name} -> R2: {metrics.get('R2', float('nan')):.4f}, SignAcc: {metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "# Преобразование результатов (V2) в DataFrame\n",
    "results_df_V2 = pd.DataFrame(all_experiment_results_V2)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты с V2 наборами признаков завершены!\")\n",
    "if not results_df_V2.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами (V2 Features):\")\n",
    "    print(results_df_V2.head())\n",
    "    \n",
    "    # Сохранение результатов в CSV (опционально)\n",
    "    # results_df_V2.to_csv('market_prediction_experiment_results_V2.csv', index=False)\n",
    "    # print(\"\\nРезультаты (V2) сохранены в market_prediction_experiment_results_V2.csv\")\n",
    "else:\n",
    "    print(\"DataFrame с результатами (V2 Features) пуст. Проверьте логи и возможные ошибки.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Новая ячейка для задач классификации ---\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "# Остальные необходимые импорты, такие как train_test_split, RandomizedSearchCV, np, pd, lgb, xgb\n",
    "# предполагаются импортированными в предыдущих ячейках или будут добавлены сюда при необходимости.\n",
    "\n",
    "def train_and_evaluate_classifier_models(df, features, binary_target_col, ticker_name, test_size=0.2, n_iter_search=10, cv_search=3):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модели бинарной классификации (пока только LogisticRegression)\n",
    "    с подбором гиперпараметров через RandomizedSearchCV.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame с данными (уже с бинарным таргетом).\n",
    "        features (list): Список названий признаков для обучения.\n",
    "        binary_target_col (str): Название бинарной целевой переменной (0 или 1).\n",
    "        ticker_name (str): Имя тикера (для информации).\n",
    "        test_size (float): Доля данных для тестовой выборки.\n",
    "        n_iter_search (int): Количество итераций для RandomizedSearchCV.\n",
    "        cv_search (int): Количество фолдов кросс-валидации для RandomizedSearchCV.\n",
    "\n",
    "    Returns:\n",
    "        dict: Словарь с метриками и лучшими параметрами для каждой модели.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    current_features = [f for f in features if f in df.columns]\n",
    "    if not current_features:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] Ни один из указанных признаков не найден. Пропуск.\")\n",
    "        return {}\n",
    "    if binary_target_col not in df.columns:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] Целевая переменная '{binary_target_col}' не найдена. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    # Убедимся, что таргет не содержит пропусков после его создания и перед использованием\n",
    "    df_clean = df[current_features + [binary_target_col]].copy()\n",
    "    df_clean.dropna(subset=[binary_target_col], inplace=True) # Удаляем строки, где бинарный таргет NaN (было target == 0)\n",
    "    \n",
    "    # Также удаляем строки, где признаки или сам таргет (после предыдущего dropna) могут быть NaN\n",
    "    df_clean.dropna(inplace=True)\n",
    "\n",
    "    if df_clean.empty:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] DataFrame пуст после удаления NaN (возможно, все таргеты были 0 или NaN). Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X = df_clean[current_features]\n",
    "    y = df_clean[binary_target_col]\n",
    "\n",
    "    # Проверим, что у нас как минимум два класса в y после всех очисток\n",
    "    if y.nunique() < 2:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] Обнаружен только один класс в целевой переменной после очистки NaN. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    if X.empty or len(y) < (1/test_size) + cv_search: \n",
    "        print(f\"[{ticker_name} - {binary_target_col}] Недостаточно данных для обучения/тестирования/CV ({X.shape}, y: {y.shape}). Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False, stratify=None)\n",
    "    # Для временных рядов stratify=None обычно лучше, но если классы сильно несбалансированы, можно рассмотреть stratify=y.\n",
    "    # Однако, shuffle=False важнее для временной структуры.\n",
    "\n",
    "    if X_train.empty or X_test.empty or len(X_train) < cv_search or len(y_train) < cv_search:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] Тренировочная/тестовая выборка или данных для CV недостаточно. Пропуск.\")\n",
    "        return {}\n",
    "    \n",
    "    # Проверка на наличие хотя бы двух классов в y_train для стратифицированной CV, если она используется\n",
    "    # RandomizedSearchCV с некоторыми CV стратегиями может требовать этого.\n",
    "    if y_train.nunique() < 2:\n",
    "        print(f\"[{ticker_name} - {binary_target_col}] В y_train ({len(y_train)} семплов) только один класс. Пропуск RandomizedSearchCV.\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "    # Определение базовых моделей\n",
    "    base_logreg = LogisticRegression(random_state=42, max_iter=1000) # Увеличим max_iter для некоторых солверов\n",
    "\n",
    "    # Сетки параметров для RandomizedSearchCV\n",
    "    param_dist_logreg = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'] # 'liblinear' хорошо работает с l1/l2, 'saga' тоже универсальна\n",
    "    }\n",
    "    # Убедимся, что комбинации penalty/solver валидны: l1 с liblinear/saga, l2 с liblinear/saga\n",
    "    # RandomizedSearchCV переберет только валидные.\n",
    "\n",
    "    models_config = {\n",
    "        'LogisticRegression': (base_logreg, param_dist_logreg),\n",
    "    }\n",
    "\n",
    "    classification_scorers = {\n",
    "        'Accuracy': accuracy_score,\n",
    "        'ROC_AUC': roc_auc_score,\n",
    "        'F1_Score': f1_score,\n",
    "        'Precision': precision_score,\n",
    "        'Recall': recall_score\n",
    "    }\n",
    "\n",
    "    for model_name, (model_base, params) in models_config.items():\n",
    "        print(f\"  Подбор параметров для {model_name} (классификация), таргет {binary_target_col}...\")\n",
    "        \n",
    "        # Убедимся, что в y_train достаточно семплов каждого класса для cv_search фолдов, если CV стратифицированный\n",
    "        # Для простой CV это менее критично, но min_samples_per_fold для CV важно\n",
    "        current_cv = min(cv_search, y_train.value_counts().min()) if y_train.nunique() > 1 else cv_search \n",
    "        if len(X_train) < 2 or current_cv < 2 : # RandomizedSearchCV требует как минимум 2 фолда и достаточно данных\n",
    "             print(f\"    Недостаточно данных в X_train ({len(X_train)}) или y_train ({y_train.value_counts().min()} min class samples) для кросс-валидации с {current_cv} фолдами. Пропуск {model_name}.\")\n",
    "             results[model_name] = {metric: np.nan for metric in classification_scorers.keys()}\n",
    "             results[model_name]['best_params'] = {}\n",
    "             continue\n",
    "\n",
    "        try:\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=model_base, \n",
    "                param_distributions=params, \n",
    "                n_iter=n_iter_search, \n",
    "                cv=current_cv, \n",
    "                scoring='roc_auc', # Оптимизируем по ROC AUC\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                error_score='raise' # Чтобы видеть ошибки подбора\n",
    "            )\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            best_model = search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.predict_proba(X_test)[:, 1] # Вероятности для ROC AUC\n",
    "            \n",
    "            model_metrics = {}\n",
    "            for metric_name, scorer_func in classification_scorers.items():\n",
    "                if metric_name == 'ROC_AUC':\n",
    "                    # roc_auc_score требует y_score (вероятности) для бинарной классификации\n",
    "                    if y_test.nunique() < 2:\n",
    "                        model_metrics[metric_name] = np.nan # Нельзя посчитать ROC AUC если в y_test только один класс\n",
    "                    else:\n",
    "                        model_metrics[metric_name] = scorer_func(y_test, y_pred_proba)\n",
    "                else:\n",
    "                    model_metrics[metric_name] = scorer_func(y_test, y_pred)\n",
    "            \n",
    "            model_metrics['best_params'] = search.best_params_\n",
    "            results[model_name] = model_metrics\n",
    "            print(f\"    {model_name} (tuned) ROC_AUC: {model_metrics.get('ROC_AUC', float('nan')):.4f}, Accuracy: {model_metrics.get('Accuracy', float('nan')):.4f}\")\n",
    "\n",
    "        except ValueError as ve:\n",
    "            # Отлавливаем ValueError, который часто возникает при проблемах с классами или солверами\n",
    "            print(f\"ValueError при подборе/обучении модели {model_name} для {binary_target_col} тикера {ticker_name}: {ve}\")\n",
    "            results[model_name] = {metric: np.nan for metric in classification_scorers.keys()} \n",
    "            results[model_name]['best_params'] = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Общая ошибка при подборе/обучении модели {model_name} для {binary_target_col} тикера {ticker_name}: {e}\")\n",
    "            results[model_name] = {metric: np.nan for metric in classification_scorers.keys()} \n",
    "            results[model_name]['best_params'] = {}\n",
    "            \n",
    "    return results\n",
    "\n",
    "print(\"Функция train_and_evaluate_classifier_models определена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Основной цикл для экспериментов Классификации ===\n",
    "\n",
    "# tickers_to_process, data_path_template, targets, \n",
    "# selected_base_features_template, n_iterations_rscv, cv_folds_rscv\n",
    "# должны быть определены в предыдущих ячейках.\n",
    "\n",
    "all_classification_results_V2 = []\n",
    "\n",
    "for ticker in tickers_to_process: # Используем тот же список тикеров\n",
    "    print(f\"\\nProcessing CLASSIFICATION for Ticker (V2 Features): {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker_orig = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker_orig.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # --- Создание копии DataFrame для добавления бинарных таргетов ---\n",
    "    df_ticker_clf = df_ticker_orig.copy()\n",
    "\n",
    "    # --- Создание бинарных целевых переменных ---\n",
    "    binary_target_columns = []\n",
    "    for reg_target_col in targets: # targets = ['target_1d', 'target_3d', ...]\n",
    "        if reg_target_col in df_ticker_clf.columns:\n",
    "            clf_target_col_name = f\"{reg_target_col}_clf\"\n",
    "            binary_target_columns.append(clf_target_col_name)\n",
    "            \n",
    "            # Преобразуем в числовой тип перед созданием бинарного таргета, если еще не сделано\n",
    "            df_ticker_clf[reg_target_col] = pd.to_numeric(df_ticker_clf[reg_target_col], errors='coerce')\n",
    "\n",
    "            df_ticker_clf[clf_target_col_name] = np.nan # Инициализируем NaN\n",
    "            df_ticker_clf.loc[df_ticker_clf[reg_target_col] > 0, clf_target_col_name] = 1\n",
    "            df_ticker_clf.loc[df_ticker_clf[reg_target_col] < 0, clf_target_col_name] = 0\n",
    "            # Случаи, где reg_target_col == 0 или был NaN, останутся NaN в clf_target_col_name\n",
    "            # и будут удалены внутри train_and_evaluate_classifier_models\n",
    "            \n",
    "            # Проверка количества созданных классов\n",
    "            # print(f\"  Для {clf_target_col_name}: {df_ticker_clf[clf_target_col_name].value_counts(dropna=False)}\")\n",
    "        else:\n",
    "            print(f\"    Регрессионный таргет {reg_target_col} не найден для {ticker}, бинарный таргет не создан.\")\n",
    "\n",
    "    if not binary_target_columns:\n",
    "        print(f\"Ни одного бинарного таргета не было создано для {ticker}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # --- Определение наборов признаков (используем те же V2, что и для регрессии) ---\n",
    "    actual_selected_base_features = [f for f in selected_base_features_template if f in df_ticker_clf.columns]\n",
    "    if not actual_selected_base_features:\n",
    "        print(f\"Ни один из выбранных базовых признаков (V2) не найден для {ticker}. Пропуск тикера для классификации.\")\n",
    "        continue\n",
    "    # print(f\"Для {ticker} (Классификация V2): Используется {len(actual_selected_base_features)} выбранных базовых признаков.\")\n",
    "\n",
    "    current_news_features_specific = [f'{ticker}_news_score', f'{ticker}_news_score_roll_avg_5', f'{ticker}_news_score_roll_avg_15', f'{ticker}_news_score_roll_avg_30']\n",
    "    current_blog_features_specific = [f'{ticker}_blog_score', f'{ticker}_blog_score_roll_avg_5', f'{ticker}_blog_score_roll_avg_15', f'{ticker}_blog_score_roll_avg_30']\n",
    "    \n",
    "    actual_news_features_specific = [f for f in current_news_features_specific if f in df_ticker_clf.columns]\n",
    "    actual_blog_features_specific = [f for f in current_blog_features_specific if f in df_ticker_clf.columns]\n",
    "\n",
    "    feature_sets_defs_V2 = {\n",
    "        \"BaseFeatures_V2\": actual_selected_base_features,\n",
    "        \"BasePlusNews_V2\": actual_selected_base_features + actual_news_features_specific,\n",
    "        \"BasePlusNewsBlogs_V2\": actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific\n",
    "    }\n",
    "\n",
    "    # --- Принудительное преобразование признаков в числовой формат (для df_ticker_clf) ---\n",
    "    # Это важно делать на копии, которая будет передаваться в функцию\n",
    "    # Эта операция должна быть выполнена один раз для всех признаков, которые могут быть использованы.\n",
    "    all_possible_features_for_clf = list(set(actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific))\n",
    "    for col_to_convert in all_possible_features_for_clf:\n",
    "        if col_to_convert in df_ticker_clf.columns:\n",
    "             df_ticker_clf[col_to_convert] = pd.to_numeric(df_ticker_clf[col_to_convert], errors='coerce')\n",
    "\n",
    "    # --- Цикл по бинарным таргетам и наборам признаков ---\n",
    "    for clf_target_col in binary_target_columns:\n",
    "        print(f\"\\n  Processing CLF Target: {clf_target_col} for Ticker: {ticker}\")\n",
    "        \n",
    "        # Проверка, что таргет все еще существует и не пуст после всех манипуляций\n",
    "        if clf_target_col not in df_ticker_clf.columns or df_ticker_clf[clf_target_col].isnull().all():\n",
    "            print(f\"    Бинарный таргет {clf_target_col} пуст или отсутствует для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "        if df_ticker_clf[clf_target_col].nunique(dropna=True) < 2:\n",
    "            print(f\"    В бинарном таргете {clf_target_col} для {ticker} менее двух уникальных классов после создания. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs_V2.items():\n",
    "            print(f\"\\n    Training CLF with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            unique_fs_features = sorted(list(set(fs_features)))\n",
    "            if not unique_fs_features:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {clf_target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            # Передаем df_ticker_clf, который уже содержит бинарные таргеты и числовые признаки\n",
    "            clf_model_metrics_results = train_and_evaluate_classifier_models(\n",
    "                df_ticker_clf, # DataFrame с уже созданными бинарными таргетами и числовыми признаками\n",
    "                unique_fs_features, \n",
    "                clf_target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in clf_model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': clf_target_col, # Используем имя бинарного таргета\n",
    "                    'FeatureSet': fs_name, \n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics)\n",
    "                all_classification_results_V2.append(result_row)\n",
    "                \n",
    "                if metrics and 'ROC_AUC' in metrics :\n",
    "                    print(f\"      {model_name} for {fs_name} (CLF) -> ROC_AUC: {metrics.get('ROC_AUC', float('nan')):.4f}, Accuracy: {metrics.get('Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} (CLF) -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "# Преобразование результатов классификации в DataFrame\n",
    "results_clf_df_V2 = pd.DataFrame(all_classification_results_V2)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты по Классификации (V2 Features) завершены!\")\n",
    "if not results_clf_df_V2.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами Классификации (V2 Features):\")\n",
    "    print(results_clf_df_V2.head())\n",
    "    \n",
    "    # results_clf_df_V2.to_csv('market_classification_experiment_results_V2.csv', index=False)\n",
    "    # print(\"\\nРезультаты Классификации (V2) сохранены в market_classification_experiment_results_V2.csv\")\n",
    "else:\n",
    "    print(\"DataFrame с результатами Классификации (V2 Features) пуст. Проверьте логи.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл исследования (с ЯВНО ЗАДАННЫМИ V2 наборами признаков и исправлением типов)\n",
    "\n",
    "tickers_to_process = ['LKOH', 'SBER', 'GAZP']\n",
    "data_path_template = '../data/features_final/{}_final.csv'\n",
    "\n",
    "all_experiment_results_V2 = [] \n",
    "\n",
    "# Параметры для RandomizedSearchCV\n",
    "n_iterations_rscv = 10 \n",
    "cv_folds_rscv = 3      \n",
    "\n",
    "# ЯВНО ЗАДАННЫЙ список \"самых важных\" базовых признаков (37 шт.)\n",
    "selected_base_features_template = [\n",
    "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', \n",
    "    'RSI', 'MACD_Hist', 'Bear_Power', 'ATR', 'EMA_10', 'EMA_50', 'EMA_200', 'RTSI', 'EMV', 'ADX',\n",
    "    'MOEXCN', 'MOEXIT', 'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM', 'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH',\n",
    "    'Revenue_y', 'NetProfit_y', 'ROE_y', 'Assets_q', 'NetProfit_q', 'PB_q',\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'USD_RUB',\n",
    "    'PE_y', 'PB_y'\n",
    "]\n",
    "\n",
    "for ticker in tickers_to_process:\n",
    "    print(f\"\\nProcessing Ticker (V2 Features): {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker_orig = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker_orig.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    actual_selected_base_features = [f for f in selected_base_features_template if f in df_ticker_orig.columns]\n",
    "    if not actual_selected_base_features:\n",
    "        print(f\"Ни один из выбранных базовых признаков не найден для {ticker}. Пропуск тикера.\")\n",
    "        continue\n",
    "    print(f\"Для {ticker} (V2): Используется {len(actual_selected_base_features)} выбранных базовых признаков.\")\n",
    "\n",
    "    # ЯВНО ЗАДАННЫЕ списки новостных и блоговых признаков\n",
    "    current_news_features_specific = [\n",
    "        f'{ticker}_news_score', \n",
    "        f'{ticker}_news_score_roll_avg_5',\n",
    "        f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score' # Оставляем, как в вашем примере\n",
    "    ]\n",
    "    current_blog_features_specific = [\n",
    "        f'{ticker}_blog_score',\n",
    "        f'{ticker}_blog_score_roll_avg_5',\n",
    "        f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score' # Оставляем, как в вашем примере\n",
    "    ]\n",
    "    \n",
    "    actual_news_features_specific = [f for f in current_news_features_specific if f in df_ticker_orig.columns]\n",
    "    actual_blog_features_specific = [f for f in current_blog_features_specific if f in df_ticker_orig.columns]\n",
    "\n",
    "    feature_sets_defs_V2 = {\n",
    "        \"BaseFeatures_V2\": actual_selected_base_features,\n",
    "        \"BasePlusNews_V2\": actual_selected_base_features + actual_news_features_specific,\n",
    "        \"BasePlusNewsBlogs_V2\": actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific\n",
    "    }\n",
    "\n",
    "    for target_col in targets: \n",
    "        print(f\"\\n  Processing Target: {target_col} for Ticker: {ticker} (V2 Features)\")\n",
    "        if target_col not in df_ticker_orig.columns:\n",
    "            print(f\"    Целевая переменная {target_col} отсутствует в данных для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "        if df_ticker_orig[target_col].isnull().all() or df_ticker_orig[target_col].nunique() < 2:\n",
    "            print(f\"    Целевая переменная {target_col} для {ticker} содержит все NaN или одно уникальное значение. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs_V2.items():\n",
    "            print(f\"\\n    Training with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            unique_fs_features = sorted(list(set(fs_features)))\n",
    "            if not unique_fs_features:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            df_loop_copy = df_ticker_orig.copy()\n",
    "\n",
    "            for col_to_convert in unique_fs_features + [target_col]:\n",
    "                if col_to_convert in df_loop_copy.columns:\n",
    "                    df_loop_copy[col_to_convert] = pd.to_numeric(df_loop_copy[col_to_convert], errors='coerce')\n",
    "            \n",
    "            if df_loop_copy[target_col].isnull().all():\n",
    "                print(f\"      Целевая переменная {target_col} для {ticker} стала полностью NaN после pd.to_numeric. Пропуск набора.\")\n",
    "                continue\n",
    "\n",
    "            model_metrics_results = train_and_evaluate_models(\n",
    "                df_loop_copy, \n",
    "                unique_fs_features, \n",
    "                target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': target_col,\n",
    "                    'FeatureSet': fs_name, \n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics)\n",
    "                all_experiment_results_V2.append(result_row)\n",
    "                \n",
    "                if metrics and 'R2' in metrics :\n",
    "                    print(f\"      {model_name} for {fs_name} -> R2: {metrics.get('R2', float('nan')):.4f}, SignAcc: {metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "results_df_V2 = pd.DataFrame(all_experiment_results_V2)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты с V2 (явные признаки) наборами признаков завершены!\")\n",
    "if not results_df_V2.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами (V2 Features):\")\n",
    "    print(results_df_V2.head())\n",
    "else:\n",
    "    print(\"DataFrame с результатами (V2 Features) пуст. Проверьте логи и возможные ошибки.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Основной цикл для экспериментов Классификации (с ЯВНО ЗАДАННЫМИ V2 признаками) ===\n",
    "\n",
    "# tickers_to_process, data_path_template, targets, \n",
    "# n_iterations_rscv, cv_folds_rscv должны быть определены.\n",
    "# selected_base_features_template также должен быть определен (возьмем из ячейки регрессии V2)\n",
    "\n",
    "all_classification_results_V2 = []\n",
    "\n",
    "# ЯВНО ЗАДАННЫЙ список \"самых важных\" базовых признаков (37 шт.) - должен быть тот же, что и для регрессии V2\n",
    "selected_base_features_template = [\n",
    "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', \n",
    "    'RSI', 'MACD_Hist', 'Bear_Power', 'ATR', 'EMA_10', 'EMA_50', 'EMA_200', 'RTSI', 'EMV', 'ADX',\n",
    "    'MOEXCN', 'MOEXIT', 'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM', 'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH',\n",
    "    'Revenue_y', 'NetProfit_y', 'ROE_y', 'Assets_q', 'NetProfit_q', 'PB_q',\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'USD_RUB',\n",
    "    'PE_y', 'PB_y'\n",
    "]\n",
    "\n",
    "for ticker in tickers_to_process: \n",
    "    print(f\"\\nProcessing CLASSIFICATION for Ticker (V2 Features): {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker_orig = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker_orig.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    df_ticker_clf = df_ticker_orig.copy()\n",
    "\n",
    "    binary_target_columns = []\n",
    "    for reg_target_col in targets: \n",
    "        if reg_target_col in df_ticker_clf.columns:\n",
    "            clf_target_col_name = f\"{reg_target_col}_clf\"\n",
    "            binary_target_columns.append(clf_target_col_name)\n",
    "            df_ticker_clf[reg_target_col] = pd.to_numeric(df_ticker_clf[reg_target_col], errors='coerce')\n",
    "            df_ticker_clf[clf_target_col_name] = np.nan\n",
    "            df_ticker_clf.loc[df_ticker_clf[reg_target_col] > 0, clf_target_col_name] = 1\n",
    "            df_ticker_clf.loc[df_ticker_clf[reg_target_col] < 0, clf_target_col_name] = 0\n",
    "        else:\n",
    "            print(f\"    Регрессионный таргет {reg_target_col} не найден для {ticker}, бинарный таргет не создан.\")\n",
    "\n",
    "    if not binary_target_columns:\n",
    "        print(f\"Ни одного бинарного таргета не было создано для {ticker}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    actual_selected_base_features = [f for f in selected_base_features_template if f in df_ticker_clf.columns]\n",
    "    if not actual_selected_base_features:\n",
    "        print(f\"Ни один из выбранных базовых признаков (V2) не найден для {ticker}. Пропуск тикера для классификации.\")\n",
    "        continue\n",
    "\n",
    "    # ЯВНО ЗАДАННЫЕ списки новостных и блоговых признаков (те же, что и для регрессии V2)\n",
    "    current_news_features_specific = [\n",
    "        f'{ticker}_news_score', \n",
    "        f'{ticker}_news_score_roll_avg_5',\n",
    "        f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score' \n",
    "    ]\n",
    "    current_blog_features_specific = [\n",
    "        f'{ticker}_blog_score',\n",
    "        f'{ticker}_blog_score_roll_avg_5',\n",
    "        f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score' \n",
    "    ]\n",
    "        \n",
    "    actual_news_features_specific = [f for f in current_news_features_specific if f in df_ticker_clf.columns]\n",
    "    actual_blog_features_specific = [f for f in current_blog_features_specific if f in df_ticker_clf.columns]\n",
    "\n",
    "    feature_sets_defs_V2 = {\n",
    "        \"BaseFeatures_V2\": actual_selected_base_features,\n",
    "        \"BasePlusNews_V2\": actual_selected_base_features + actual_news_features_specific,\n",
    "        \"BasePlusNewsBlogs_V2\": actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific\n",
    "    }\n",
    "\n",
    "    all_possible_features_for_clf = list(set(actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific))\n",
    "    for col_to_convert in all_possible_features_for_clf:\n",
    "        if col_to_convert in df_ticker_clf.columns:\n",
    "             df_ticker_clf[col_to_convert] = pd.to_numeric(df_ticker_clf[col_to_convert], errors='coerce')\n",
    "\n",
    "    for clf_target_col in binary_target_columns:\n",
    "        print(f\"\\n  Processing CLF Target: {clf_target_col} for Ticker: {ticker}\")\n",
    "        \n",
    "        if clf_target_col not in df_ticker_clf.columns or df_ticker_clf[clf_target_col].isnull().all():\n",
    "            print(f\"    Бинарный таргет {clf_target_col} пуст или отсутствует для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "        if df_ticker_clf[clf_target_col].nunique(dropna=True) < 2:\n",
    "            print(f\"    В бинарном таргете {clf_target_col} для {ticker} менее двух уникальных классов после создания. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs_V2.items():\n",
    "            print(f\"\\n    Training CLF with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            unique_fs_features = sorted(list(set(fs_features)))\n",
    "            if not unique_fs_features:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {clf_target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            clf_model_metrics_results = train_and_evaluate_classifier_models(\n",
    "                df_ticker_clf, \n",
    "                unique_fs_features, \n",
    "                clf_target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in clf_model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': clf_target_col, \n",
    "                    'FeatureSet': fs_name, \n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics)\n",
    "                all_classification_results_V2.append(result_row)\n",
    "                \n",
    "                if metrics and 'ROC_AUC' in metrics :\n",
    "                    print(f\"      {model_name} for {fs_name} (CLF) -> ROC_AUC: {metrics.get('ROC_AUC', float('nan')):.4f}, Accuracy: {metrics.get('Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} (CLF) -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "results_clf_df_V2 = pd.DataFrame(all_classification_results_V2)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты по Классификации (V2, явные признаки) завершены!\")\n",
    "if not results_clf_df_V2.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами Классификации (V2 Features):\")\n",
    "    print(results_clf_df_V2.head())\n",
    "else:\n",
    "    print(\"DataFrame с результатами Классификации (V2 Features) пуст. Проверьте логи.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
