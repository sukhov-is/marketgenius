{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error, mean_absolute_percentage_error, explained_variance_score, max_error, accuracy_score \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np \n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "# from catboost import CatBoostRegressor # CatBoost убран\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для расчета точности определения знака\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "# Загрузка данных\n",
    "# Убедитесь, что путь к файлу указан верно\n",
    "try:\n",
    "    lkoh_df = pd.read_csv('../data/features_final/LKOH_final.csv')\n",
    "    print(\"Данные для LKOH загружены успешно.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл LKOH_final.csv не найден. Проверьте путь к файлу.\")\n",
    "    # Можно добавить код для загрузки других тикеров или обработки ошибки\n",
    "\n",
    "# Определение целевых переменных\n",
    "targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Определение признаков оценки новостей для LKOH\n",
    "# Для других тикеров 'LKOH' нужно будет заменить на соответствующий тикер\n",
    "ticker_prefix = 'LKOH' # Это нужно будет менять для других тикеров\n",
    "\n",
    "news_features = [\n",
    "    f'{ticker_prefix}_news_score', f'{ticker_prefix}_news_score_roll_avg_5', \n",
    "    f'{ticker_prefix}_news_score_roll_avg_15', f'{ticker_prefix}_news_score_roll_avg_30',\n",
    "    'WeightedIndices_news_score', 'WeightedIndices_news_score_roll_avg_5', \n",
    "    'WeightedIndices_news_score_roll_avg_15', 'WeightedIndices_news_score_roll_avg_30'\n",
    "]\n",
    "\n",
    "# Определение признаков оценки блогов для LKOH\n",
    "blog_features = [\n",
    "    f'{ticker_prefix}_blog_score', f'{ticker_prefix}_blog_score_roll_avg_5', \n",
    "    f'{ticker_prefix}_blog_score_roll_avg_15', f'{ticker_prefix}_blog_score_roll_avg_30',\n",
    "    'WeightedIndices_blog_score', 'WeightedIndices_blog_score_roll_avg_5', \n",
    "    'WeightedIndices_blog_score_roll_avg_15', 'WeightedIndices_blog_score_roll_avg_30'\n",
    "]\n",
    "\n",
    "# Определение базовых признаков \n",
    "# (все, кроме целевых, новостных и блоговых, а также исключаем 'Date' и 'Ticker' и другие специфичные для таргетов колонки)\n",
    "# Сначала получим все колонки\n",
    "all_columns = lkoh_df.columns.tolist()\n",
    "\n",
    "# Колонки, которые точно не являются признаками\n",
    "excluded_columns = targets + news_features + blog_features + ['Date', 'Ticker']\n",
    "\n",
    "# Дополнительно убедимся, что не включаем колонки, которые могут содержать информацию о будущем или являются вариациями таргетов\n",
    "# Например, если есть колонки типа 'price_change_next_N_days' и т.п., их тоже надо исключить.\n",
    "# В данном случае, предполагаем, что остальные колонки - это базовые признаки.\n",
    "base_features = [col for col in all_columns if col not in excluded_columns]\n",
    "\n",
    "# Удалим признаки, которые могут содержать NaN из-за rolling averages на начальных этапах, если они есть только в начале\n",
    "# Это специфично для данных и требует их анализа. Пока оставим как есть.\n",
    "# lkoh_df.dropna(subset=base_features + news_features + blog_features, inplace=True) # Раскомментировать и адаптировать при необходимости\n",
    "\n",
    "\n",
    "print(f\"Количество базовых признаков: {len(base_features)}\")\n",
    "if len(base_features) > 0:\n",
    "    print(f\"Пример базовых признаков: {base_features[:5]}...\")\n",
    "else:\n",
    "    print(\"Базовые признаки не определены. Проверьте логику исключения колонок.\")\n",
    "    \n",
    "print(f\"Новостные признаки: {news_features}\")\n",
    "print(f\"Блоговые признаки: {blog_features}\")\n",
    "\n",
    "# Проверка наличия всех признаков в DataFrame\n",
    "missing_news_features = [f for f in news_features if f not in lkoh_df.columns]\n",
    "missing_blog_features = [f for f in blog_features if f not in lkoh_df.columns]\n",
    "missing_base_features = [f for f in base_features if f not in lkoh_df.columns] # Хотя это должно быть пусто по определению\n",
    "\n",
    "if missing_news_features:\n",
    "    print(f\"ВНИМАНИЕ: Следующие новостные признаки отсутствуют в LKOH_final.csv: {missing_news_features}\")\n",
    "if missing_blog_features:\n",
    "    print(f\"ВНИМАНИЕ: Следующие блоговые признаки отсутствуют в LKOH_final.csv: {missing_blog_features}\")\n",
    "\n",
    "# Определим наборы признаков для экспериментов:\n",
    "# 1. Только базовые признаки\n",
    "features_set_1 = base_features\n",
    "# 2. Базовые + новостные\n",
    "features_set_2 = base_features + [f for f in news_features if f in lkoh_df.columns] # Используем только существующие\n",
    "# 3. Базовые + новостные + блоговые\n",
    "features_set_3 = base_features + [f for f in news_features if f in lkoh_df.columns] + [f for f in blog_features if f in lkoh_df.columns] # Используем только существующие\n",
    "\n",
    "print(f\"\\\\nКоличество признаков в наборе 1 (базовые): {len(features_set_1)}\")\n",
    "print(f\"Количество признаков в наборе 2 (базовые + новости): {len(features_set_2)}\")\n",
    "print(f\"Количество признаков в наборе 3 (базовые + новости + блоги): {len(features_set_3)}\")\n",
    "\n",
    "# Выведем первые несколько строк датафрейма для ознакомления\n",
    "print(\"\\\\nПервые 5 строк DataFrame LKOH:\")\n",
    "print(lkoh_df.head())\n",
    "\n",
    "# Проверим типы данных и наличие пропусков в целевых переменных\n",
    "print(\"\\\\nИнформация о DataFrame LKOH:\")\n",
    "lkoh_df.info()\n",
    "\n",
    "print(\"\\\\nПроверка на пропуски в целевых переменных LKOH:\")\n",
    "print(lkoh_df[targets].isnull().sum())\n",
    "\n",
    "# Удаление строк с NaN в целевых переменных, если они есть\n",
    "# lkoh_df.dropna(subset=targets, inplace=True)\n",
    "# print(\"\\\\nРазмер DataFrame после удаления строк с NaN в таргетах:\", lkoh_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_accuracy должна быть определена глобально, обычно в первой ячейке.\n",
    "# Убедитесь, что ячейка с ее определением выполнена.\n",
    "# def sign_accuracy(y_true, y_pred):\n",
    "#    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "def train_and_evaluate_models(df, features, target_col, ticker_name, test_size=0.2, n_iter_search=10, cv_search=3):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модели регрессии (LightGBM, XGBoost) \n",
    "    с подбором гиперпараметров через RandomizedSearchCV и расширенным набором метрик.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    current_features = [f for f in features if f in df.columns]\n",
    "    if not current_features:\n",
    "        print(f\"[{ticker_name} - {target_col}] Ни один из указанных признаков не найден. Пропуск.\")\n",
    "        return {}\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"[{ticker_name} - {target_col}] Целевая переменная '{target_col}' не найдена. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X = df[current_features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    combined_df = pd.concat([X, y], axis=1)\n",
    "    combined_df.dropna(inplace=True)\n",
    "\n",
    "    if combined_df.empty:\n",
    "        print(f\"[{ticker_name} - {target_col}] DataFrame пуст после удаления NaN. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X = combined_df[current_features]\n",
    "    y = combined_df[target_col]\n",
    "\n",
    "    if X.empty or len(y) < (1/test_size) + cv_search: \n",
    "        print(f\"[{ticker_name} - {target_col}] Недостаточно данных для обучения/тестирования/CV ({X.shape}, y: {y.shape}). Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    if X_train.empty or X_test.empty or len(X_train) < cv_search or len(y_train) < cv_search:\n",
    "        print(f\"[{ticker_name} - {target_col}] Тренировочная/тестовая выборка или данных для CV недостаточно. Пропуск.\")\n",
    "        return {}\n",
    "\n",
    "    base_lgbm = lgb.LGBMRegressor(random_state=42, verbosity=-1)\n",
    "    base_xgb = xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "    param_dist_lgbm = {\n",
    "        'n_estimators': [300, 500, 800],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [20, 31, 40, 50],\n",
    "        'max_depth': [-1, 5, 10, 15],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    param_dist_xgb = {\n",
    "        'n_estimators': [300, 500, 800],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    models_config = {\n",
    "        'LGBM': (base_lgbm, param_dist_lgbm),\n",
    "        'XGBoost': (base_xgb, param_dist_xgb),\n",
    "    }\n",
    "\n",
    "    # Обновленный словарь scorers (удалена 'Accuracy')\n",
    "    scorers = {\n",
    "        'R2': r2_score,\n",
    "        'MAE': mean_absolute_error,\n",
    "        'MSE': mean_squared_error,\n",
    "        'MedAE': median_absolute_error, \n",
    "        'MAPE': mean_absolute_percentage_error, \n",
    "        'ExplainedVariance': explained_variance_score, \n",
    "        'MaxError': max_error, \n",
    "        'Sign Accuracy': sign_accuracy \n",
    "        # 'Accuracy': accuracy_score # Удалено, т.к. это для классификации\n",
    "    }\n",
    "\n",
    "    for model_name, (model_base, params) in models_config.items():\n",
    "        print(f\"  Подбор параметров для {model_name}, таргет {target_col}...\")\n",
    "        \n",
    "        current_cv = min(cv_search, len(X_train) // 2) \n",
    "        if len(X_train) < 2 or current_cv < 2: \n",
    "             print(f\"    Недостаточно данных в X_train ({len(X_train)}) для кросс-валидации с {current_cv} фолдами. Пропуск {model_name}.\")\n",
    "             # Заполняем NaN для всех метрик, включая RMSE и best_params\n",
    "             results[model_name] = {metric: np.nan for metric in scorers.keys()}\n",
    "             results[model_name]['RMSE'] = np.nan\n",
    "             results[model_name]['best_params'] = {}\n",
    "             continue\n",
    "\n",
    "        try:\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=model_base, \n",
    "                param_distributions=params, \n",
    "                n_iter=n_iter_search, \n",
    "                cv=current_cv, \n",
    "                scoring='r2', \n",
    "                random_state=42,\n",
    "                n_jobs=-1 \n",
    "            )\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            best_model = search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            model_metrics = {}\n",
    "            for metric_name, scorer_func in scorers.items():\n",
    "                if metric_name == 'MAPE' and np.any(y_test == 0):\n",
    "                    pass \n",
    "                model_metrics[metric_name] = scorer_func(y_test, y_pred)\n",
    "            \n",
    "            # Проверяем, есть ли MSE перед вычислением RMSE\n",
    "            if 'MSE' in model_metrics and not np.isnan(model_metrics['MSE']):\n",
    "                model_metrics['RMSE'] = np.sqrt(model_metrics['MSE'])\n",
    "            else:\n",
    "                model_metrics['RMSE'] = np.nan # Если MSE нет или NaN, RMSE тоже NaN\n",
    "                \n",
    "            model_metrics['best_params'] = search.best_params_\n",
    "            results[model_name] = model_metrics\n",
    "            print(f\"    {model_name} (tuned) R2: {model_metrics.get('R2', float('nan')):.4f}, Sign Acc: {model_metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при подборе/обучении модели {model_name} для {target_col} тикера {ticker_name}: {e}\")\n",
    "            # Заполняем NaN для всех метрик, включая RMSE и best_params, в случае ошибки\n",
    "            results[model_name] = {metric: np.nan for metric in scorers.keys()}\n",
    "            results[model_name]['RMSE'] = np.nan\n",
    "            results[model_name]['best_params'] = {}\n",
    "            \n",
    "    return results\n",
    "\n",
    "print(\"Функция train_and_evaluate_models обновлена: удалена метрика 'Accuracy' и улучшена обработка RMSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Читаем последние 10 строк из CSV файла\n",
    "df = pd.read_csv('../data/processed/gpt/results_gpt_blogs.csv', engine='python').tail(10)\n",
    "\n",
    "# Сохраняем копию в новый файл\n",
    "output_path = '../data/processed/gpt/results_gpt_blogs_last_10.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Копия последних 10 строк сохранена в {output_path}\")\n",
    "print(\"\\nСодержимое файла:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_process = ['LKOH', 'SBER', 'GAZP'] # Добавьте сюда другие тикеры при необходимости\n",
    "data_path_template = '../data/features_final/{}_final.csv'\n",
    "\n",
    "all_experiment_results = []\n",
    "\n",
    "# Глобально определенные целевые переменные (из предыдущей ячейки)\n",
    "# targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Параметры для RandomizedSearchCV (можно настроить)\n",
    "n_iterations_rscv = 30 # Уменьшено для скорости, можно увеличить для более тщательного поиска\n",
    "cv_folds_rscv = 3      # Количество фолдов\n",
    "\n",
    "for ticker in tickers_to_process:\n",
    "    print(f\"\\nProcessing Ticker: {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # Динамическое определение новостных и блоговых признаков\n",
    "    current_news_features = [\n",
    "        f'{ticker}_news_score', f'{ticker}_news_score_roll_avg_5', \n",
    "        f'{ticker}_news_score_roll_avg_15', f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score', 'WeightedIndices_news_score_roll_avg_5', \n",
    "        'WeightedIndices_news_score_roll_avg_15', 'WeightedIndices_news_score_roll_avg_30'\n",
    "    ]\n",
    "    current_blog_features = [\n",
    "        f'{ticker}_blog_score', f'{ticker}_blog_score_roll_avg_5', \n",
    "        f'{ticker}_blog_score_roll_avg_15', f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score', 'WeightedIndices_blog_score_roll_avg_5', \n",
    "        'WeightedIndices_blog_score_roll_avg_15', 'WeightedIndices_blog_score_roll_avg_30'\n",
    "    ]\n",
    "\n",
    "    # Отфильтруем только существующие в данном датасете признаки\n",
    "    actual_news_features = [f for f in current_news_features if f in df_ticker.columns]\n",
    "    actual_blog_features = [f for f in current_blog_features if f in df_ticker.columns]\n",
    "\n",
    "    # Определение базовых признаков\n",
    "    all_columns = df_ticker.columns.tolist()\n",
    "    excluded_for_base = targets + actual_news_features + actual_blog_features\n",
    "    # Добавим стандартные колонки, не являющиеся признаками (учитываем разные написания Date/date)\n",
    "    potential_non_features = ['DATE', 'date', 'Ticker', 'SECID', 'TRADEDATE', 'tradetimestamp'] \n",
    "    for col_name in potential_non_features:\n",
    "        if col_name in all_columns and col_name not in excluded_for_base:\n",
    "            excluded_for_base.append(col_name)\n",
    "    \n",
    "    current_base_features = [col for col in all_columns if col not in excluded_for_base]\n",
    "    \n",
    "    if not current_base_features:\n",
    "        print(f\"Не найдено базовых признаков для {ticker} после исключения. Проверьте логику! Пропуск тикера.\")\n",
    "        continue\n",
    "    print(f\"Для {ticker}: Найдено {len(current_base_features)} базовых признаков.\")\n",
    "\n",
    "    # Определяем наборы признаков для экспериментов\n",
    "    feature_sets_defs = {\n",
    "        \"BaseFeatures\": current_base_features,\n",
    "        \"BasePlusNews\": current_base_features + actual_news_features,\n",
    "        \"BasePlusNewsBlogs\": current_base_features + actual_news_features + actual_blog_features\n",
    "    }\n",
    "\n",
    "    for target_col in targets:\n",
    "        print(f\"\\n  Processing Target: {target_col} for Ticker: {ticker}\")\n",
    "        if target_col not in df_ticker.columns:\n",
    "            print(f\"    Целевая переменная {target_col} отсутствует в данных для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "            \n",
    "        # Проверка на наличие достаточного количества не-NaN значений в таргете\n",
    "        if df_ticker[target_col].isnull().all() or df_ticker[target_col].nunique() < 2:\n",
    "            print(f\"    Целевая переменная {target_col} для {ticker} содержит все NaN или только одно уникальное значение. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs.items():\n",
    "            print(f\"\\n    Training with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            # Убедимся, что в fs_features нет дубликатов (на случай если base уже содержал news/blog из-за ошибки в именовании)\n",
    "            unique_fs_features = sorted(list(set(fs_features)))\n",
    "            if len(unique_fs_features) == 0:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            # Создаем копию DataFrame для каждой итерации, чтобы избежать модификации оригинала при удалении NaNs\n",
    "            # и для обработки NaNs специфично для текущего набора признаков и таргета\n",
    "            df_loop_copy = df_ticker.copy()\n",
    "\n",
    "            model_metrics_results = train_and_evaluate_models(\n",
    "                df_loop_copy, \n",
    "                unique_fs_features, \n",
    "                target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': target_col,\n",
    "                    'FeatureSet': fs_name,\n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics) # Добавляем все метрики и best_params\n",
    "                all_experiment_results.append(result_row)\n",
    "                \n",
    "                if metrics and 'R2' in metrics : # Проверяем что метрики не пустые\n",
    "                    print(f\"      {model_name} for {fs_name} -> R2: {metrics.get('R2', float('nan')):.4f}, SignAcc: {metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "# Преобразование результатов в DataFrame\n",
    "results_df = pd.DataFrame(all_experiment_results)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты завершены!\")\n",
    "if not results_df.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    # Сохранение результатов в CSV (опционально)\n",
    "    # results_df.to_csv('market_prediction_experiment_results.csv', index=False)\n",
    "    # print(\"\\nРезультаты сохранены в market_prediction_experiment_results.csv\")\n",
    "else:\n",
    "    print(\"DataFrame с результатами пуст. Проверьте логи и возможные ошибки.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkoh_df = pd.read_csv('../data/features_final/LKOH_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkoh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл исследования (с обновленными наборами признаков)\n",
    "\n",
    "tickers_to_process = ['LKOH', 'SBER', 'GAZP']\n",
    "data_path_template = '../data/features_final/{}_final.csv'\n",
    "\n",
    "all_experiment_results_V2 = [] # Новая переменная для результатов с новым набором признаков\n",
    "\n",
    "# Определяем целевые переменные (должны быть доступны из предыдущих ячеек)\n",
    "# targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d']\n",
    "\n",
    "# Параметры для RandomizedSearchCV\n",
    "n_iterations_rscv = 50\n",
    "cv_folds_rscv = 3      \n",
    "\n",
    "# Новый, сокращенный список \"самых важных\" базовых признаков\n",
    "selected_base_features_template = [\n",
    "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', \n",
    "    'RSI', 'MACD_Hist', 'Bear_Power', 'ATR', 'EMA_10', 'EMA_50', 'EMA_200', 'RTSI', 'EMV', 'ADX',\n",
    "    'MOEXCN', 'MOEXIT', 'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM', 'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH',\n",
    "    'Revenue_y', 'NetProfit_y', 'ROE_y', 'Assets_q', 'NetProfit_q', 'PB_q',\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'USD_RUB',\n",
    "    'PE_y', 'PB_y'\n",
    "]\n",
    "\n",
    "for ticker in tickers_to_process:\n",
    "    print(f\"\\nProcessing Ticker (V2 Features): {ticker} ============\")\n",
    "    file_path = data_path_template.format(ticker)\n",
    "    \n",
    "    try:\n",
    "        df_ticker = pd.read_csv(file_path)\n",
    "        print(f\"Данные для {ticker} загружены успешно. Форма: {df_ticker.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_path} не найден. Пропуск тикера {ticker}.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных для {ticker}: {e}. Пропуск тикера.\")\n",
    "        continue\n",
    "\n",
    "    # 1. Определение актуальных базовых признаков из нашего выбранного списка\n",
    "    actual_selected_base_features = [f for f in selected_base_features_template if f in df_ticker.columns]\n",
    "    if not actual_selected_base_features:\n",
    "        print(f\"Ни один из выбранных базовых признаков не найден для {ticker}. Пропуск тикера.\")\n",
    "        continue\n",
    "    print(f\"Для {ticker} (V2): Используется {len(actual_selected_base_features)} выбранных базовых признаков.\")\n",
    "\n",
    "    # 2. Определение новостных и блоговых признаков (только для тикера, без WeightedIndices)\n",
    "    current_news_features_specific = [\n",
    "        f'{ticker}_news_score', \n",
    "        f'{ticker}_news_score_roll_avg_5',\n",
    "        f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score'\n",
    "    ]\n",
    "    current_blog_features_specific = [\n",
    "        f'{ticker}_blog_score',\n",
    "        f'{ticker}_blog_score_roll_avg_5',\n",
    "        f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score'\n",
    "    ]\n",
    "    \n",
    "    # Отфильтруем только существующие в данном датасете специфичные признаки\n",
    "    actual_news_features_specific = [f for f in current_news_features_specific if f in df_ticker.columns]\n",
    "    actual_blog_features_specific = [f for f in current_blog_features_specific if f in df_ticker.columns]\n",
    "\n",
    "    # Определяем наборы признаков для экспериментов (V2)\n",
    "    feature_sets_defs_V2 = {\n",
    "        \"BaseFeatures_V2\": actual_selected_base_features,\n",
    "        \"BasePlusNews_V2\": actual_selected_base_features + actual_news_features_specific,\n",
    "        \"BasePlusNewsBlogs_V2\": actual_selected_base_features + actual_news_features_specific + actual_blog_features_specific\n",
    "    }\n",
    "\n",
    "    for target_col in targets:\n",
    "        print(f\"\\n  Processing Target: {target_col} for Ticker: {ticker} (V2 Features)\")\n",
    "        if target_col not in df_ticker.columns:\n",
    "            print(f\"    Целевая переменная {target_col} отсутствует в данных для {ticker}. Пропуск.\")\n",
    "            continue\n",
    "        if df_ticker[target_col].isnull().all() or df_ticker[target_col].nunique() < 2:\n",
    "            print(f\"    Целевая переменная {target_col} для {ticker} содержит все NaN или одно уникальное значение. Пропуск.\")\n",
    "            continue\n",
    "\n",
    "        for fs_name, fs_features in feature_sets_defs_V2.items():\n",
    "            print(f\"\\n    Training with Feature Set: {fs_name} ({len(fs_features)} features)\")\n",
    "            \n",
    "            unique_fs_features = sorted(list(set(fs_features))) # Удаляем дубликаты, если вдруг появятся\n",
    "            if not unique_fs_features:\n",
    "                print(f\"      Набор признаков {fs_name} пуст для {ticker} - {target_col}. Пропуск.\")\n",
    "                continue\n",
    "\n",
    "            df_loop_copy = df_ticker.copy()\n",
    "            model_metrics_results = train_and_evaluate_models(\n",
    "                df_loop_copy, \n",
    "                unique_fs_features, \n",
    "                target_col, \n",
    "                ticker,\n",
    "                n_iter_search=n_iterations_rscv,\n",
    "                cv_search=cv_folds_rscv\n",
    "            )\n",
    "\n",
    "            for model_name, metrics in model_metrics_results.items():\n",
    "                result_row = {\n",
    "                    'Ticker': ticker,\n",
    "                    'Target': target_col,\n",
    "                    'FeatureSet': fs_name, # Используем новые имена наборов признаков\n",
    "                    'Model': model_name,\n",
    "                }\n",
    "                result_row.update(metrics)\n",
    "                all_experiment_results_V2.append(result_row)\n",
    "                \n",
    "                if metrics and 'R2' in metrics :\n",
    "                    print(f\"      {model_name} for {fs_name} -> R2: {metrics.get('R2', float('nan')):.4f}, SignAcc: {metrics.get('Sign Accuracy', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(f\"      {model_name} for {fs_name} -> Обучение не удалось или нет метрик.\")\n",
    "\n",
    "# Преобразование результатов (V2) в DataFrame\n",
    "results_df_V2 = pd.DataFrame(all_experiment_results_V2)\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Эксперименты с V2 наборами признаков завершены!\")\n",
    "if not results_df_V2.empty:\n",
    "    print(\"Первые несколько строк DataFrame с результатами (V2 Features):\")\n",
    "    print(results_df_V2.head())\n",
    "    \n",
    "    # Сохранение результатов в CSV (опционально)\n",
    "    # results_df_V2.to_csv('market_prediction_experiment_results_V2.csv', index=False)\n",
    "    # print(\"\\nРезультаты (V2) сохранены в market_prediction_experiment_results_V2.csv\")\n",
    "else:\n",
    "    print(\"DataFrame с результатами (V2 Features) пуст. Проверьте логи и возможные ошибки.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
