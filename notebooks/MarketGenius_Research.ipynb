{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import optuna\n",
    "\n",
    "# Импорт моделей\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier # <--- Оставлено\n",
    "\n",
    "# Импорт метрик для оценки\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Импорт для разделения выборки\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "# Настройки для отображения Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "\n",
    "# Путь к папке с файлами\n",
    "data_path = '../data/features_final/'\n",
    "\n",
    "# Загрузка индивидуальных файлов (используем SBER и ROSN как пример)\n",
    "try:\n",
    "    sber_df = pd.read_csv(os.path.join(data_path, 'SBER_final.csv'))\n",
    "    rosn_df = pd.read_csv(os.path.join(data_path, 'ROSN_final.csv'))\n",
    "    print(f\"SBER_final.csv загружен: {sber_df.shape}\")\n",
    "    print(f\"ROSN_final.csv загружен: {rosn_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Ошибка при загрузке индивидуальных файлов: {e}. Убедитесь, что файлы существуют.\")\n",
    "    # Создаем пустые датафреймы, если файлы не найдены, чтобы код ниже не падал\n",
    "    sber_df = pd.DataFrame()\n",
    "    rosn_df = pd.DataFrame()\n",
    "\n",
    "# Объединение всех файлов из папки\n",
    "all_files = glob.glob(os.path.join(data_path, \"*_final.csv\"))\n",
    "\n",
    "if not all_files:\n",
    "    print(f\"В папке {data_path} не найдено файлов *_final.csv для объединения.\")\n",
    "    all_stocks_df = pd.DataFrame() # Создаем пустой датафрейм\n",
    "else:\n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        try:\n",
    "            df_temp = pd.read_csv(filename, index_col=None, header=0)\n",
    "            df_list.append(df_temp)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при чтении файла {filename}: {e}\")\n",
    "    \n",
    "    if df_list:\n",
    "        all_stocks_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "        print(f\"\\nВсего {len(df_list)} файлов объединено в all_stocks_df.\")\n",
    "        print(f\"Размер объединенного датасета: {all_stocks_df.shape}\")\n",
    "        # print(\"\\nПервые 5 строк объединенного датасета:\")\n",
    "        # print(all_stocks_df.head())\n",
    "        # print(\"\\nИнформация о типах данных и пропусках в объединенном датасете:\")\n",
    "        # all_stocks_df.info()\n",
    "    else:\n",
    "        print(\"Не удалось загрузить ни один файл для объединения.\")\n",
    "        all_stocks_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение списков признаков и целевых переменных\n",
    "\n",
    "# Колонки, которые не являются ни признаками, ни стандартными целями\n",
    "non_feature_cols = ['date', 'SECID'] \n",
    "\n",
    "# --- Компоненты признаков ---\n",
    "price_volume_cols = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'WAPRICE']\n",
    "ma_cols = ['SMA_5', 'EMA_5', 'SMA_10', 'EMA_10', 'SMA_20', 'EMA_20', 'SMA_50', 'EMA_50', 'SMA_200', 'EMA_200']\n",
    "oscillator_cols = [\n",
    "    'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'BB_Middle', 'BB_Upper', 'BB_Lower', 'BB_Width',\n",
    "    'STOCH_K', 'STOCH_D', 'ATR', 'VWAP', 'OBV', 'OBV_MA', 'Williams_%R', 'Momentum',\n",
    "    'Plus_DI', 'Minus_DI', 'ADX', 'MFI', 'PVO', 'PVO_Signal', 'PVO_Hist', 'Chaikin_AD',\n",
    "    'Chaikin_Oscillator', 'CCI', 'EMV', 'A/D_Line', 'Bull_Power', 'Bear_Power', 'TEMA'\n",
    "]\n",
    "fundamental_cols = [\n",
    "    'Assets_q', 'Assets_y', 'CAPEX_q', 'CAPEX_y', 'Cash_q', 'Cash_y', 'Debt_q', 'Debt_y',\n",
    "    'DividendsPaid_q', 'DividendsPaid_y', 'EBITDA_q', 'EBITDA_y', 'Equity_q', 'Equity_y',\n",
    "    'NetDebt_q', 'NetDebt_y', 'NetProfit_q', 'NetProfit_y', 'OperatingCashFlow_q', 'OperatingCashFlow_y',\n",
    "    'OperatingExpenses_q', 'OperatingExpenses_y', 'OperatingProfit_q', 'OperatingProfit_y',\n",
    "    'Revenue_q', 'Revenue_y'\n",
    "]\n",
    "macro_index_cols = [\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'CPI', 'USD_RUB', 'EUR_RUB', 'CNY_RUB', 'KZT_RUB', 'TRY_RUB', 'GOLD', 'SILVER', 'NATURAL_GAS_CLOSE',\n",
    "    'MRBC', 'RTSI', 'MCXSM', 'IMOEX', 'MOEXBC', 'MOEXBMI', 'MOEXCN', 'MOEXIT', \n",
    "    'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM',\n",
    "    'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH'\n",
    "]\n",
    "relative_coeff_cols = [\n",
    "    'ROE_y', 'ROA_y', 'EBITDA_Margin_y', 'NetProfit_Margin_y', 'Debt_Equity_q', 'Debt_Equity_y',\n",
    "    'NetDebt_EBITDA_y_q', 'NetDebt_EBITDA_y_y', 'EPS_y', 'BVPS_q', 'BVPS_y', 'SPS_y',\n",
    "    'PE_y', 'PB_q', 'PB_y', 'PS_y', 'EV_EBITDA_y'\n",
    "]\n",
    "X_media_features = [\n",
    "    'score_blog', 'score_blog_roll_avg_15', 'score_blog_roll_avg_50',\n",
    "    'Index_MOEX_blog_score', 'Avg_Other_Indices_blog_score',\n",
    "    'Avg_Other_Indices_blog_score_roll_avg_15', 'Avg_Other_Indices_blog_score_roll_avg_50', \n",
    "    'score_news', 'score_news_roll_avg_15', 'score_news_roll_avg_50',\n",
    "    'Index_MOEX_news_score', 'Avg_Other_Indices_news_score', \n",
    "    'Avg_Other_Indices_news_score_roll_avg_15', 'Avg_Other_Indices_news_score_roll_avg_50'\n",
    "]\n",
    "\n",
    "# --- Основные наборы признаков ---\n",
    "# 1. Базовый набор (все, кроме медиа)\n",
    "X_base_features = price_volume_cols + ma_cols + oscillator_cols + fundamental_cols + macro_index_cols + relative_coeff_cols\n",
    "\n",
    "# 2. Расширенный набор (базовый + медиа)\n",
    "X_extended_features = X_base_features + X_media_features\n",
    "\n",
    "# 3. Технические индикаторы + Макро (Базовый - Фундаментальные - Относительные коэффициенты)\n",
    "# (media_features не входят в X_base_features, поэтому их отдельно убирать не надо из X_base_features)\n",
    "X_TECH_MACRO_features = list(set(price_volume_cols + ma_cols + oscillator_cols + macro_index_cols))\n",
    "\n",
    "# 4. Только технические индикаторы (из цен, средних, осцилляторов)\n",
    "# (X_TECH_MACRO_features - Макро)\n",
    "X_TECH_ONLY_features = list(set(price_volume_cols + ma_cols + oscillator_cols))\n",
    "\n",
    "\n",
    "# --- Целевые переменные ---\n",
    "y_reg_targets = ['target_1d', 'target_3d', 'target_7d', 'target_30d', 'target_180d', 'target_365d']\n",
    "y_clf_binary_targets = ['target_1d_binary', 'target_3d_binary', 'target_7d_binary', 'target_30d_binary', 'target_180d_binary', 'target_365d_binary']\n",
    "\n",
    "# Колонки, предназначенные для записи будущих предсказаний моделей\n",
    "existing_prediction_cols = [\n",
    "    'target_1d_pred', 'target_3d_pred', 'target_7d_pred', 'target_30d_pred', 'target_180d_pred', 'target_365d_pred'\n",
    "    'target_1d_binary_pred', 'target_3d_binary_pred', 'target_7d_binary_pred',\n",
    "    'target_30d_binary_pred', 'target_180d_binary_pred', 'target_365d_binary_pred'\n",
    "]\n",
    "\n",
    "print(f\"Количество базовых признаков (X_base): {len(X_base_features)}\")\n",
    "print(f\"Количество медиа-признаков (X_media): {len(X_media_features)}\")\n",
    "print(f\"Количество расширенных признаков (X_extended): {len(X_extended_features)}\")\n",
    "print(f\"Количество признаков в наборе Тех.Индикаторы+Макро (X_TECH_MACRO): {len(X_TECH_MACRO_features)}\")\n",
    "print(f\"Количество признаков в наборе Только Тех.Индикаторы (X_TECH_ONLY): {len(X_TECH_ONLY_features)}\")\n",
    "\n",
    "print(f\"\\nЦелевые для регрессии: {y_reg_targets}\")\n",
    "print(f\"Целевые для классификации: {y_clf_binary_targets}\")\n",
    "print(f\"Колонки для будущих предсказаний (не проверяются на наличие в исходных CSV): {existing_prediction_cols}\")\n",
    "\n",
    "# Колонки, которые ДОЛЖНЫ БЫТЬ в CSV для корректной работы скрипта:\n",
    "required_cols_for_script = list(set(\n",
    "    non_feature_cols + \n",
    "    price_volume_cols + ma_cols + oscillator_cols + fundamental_cols + macro_index_cols + relative_coeff_cols + # компоненты X_base\n",
    "    X_media_features + # компоненты X_extended\n",
    "    y_reg_targets + y_clf_binary_targets\n",
    "))\n",
    "\n",
    "if not all_stocks_df.empty:\n",
    "    missing_required_cols_in_loaded_df = []\n",
    "    for col in required_cols_for_script:\n",
    "        if col not in all_stocks_df.columns:\n",
    "            missing_required_cols_in_loaded_df.append(col)\n",
    "            \n",
    "    if missing_required_cols_in_loaded_df:\n",
    "        print(f\"\\nВНИМАНИЕ: Следующие НЕОБХОДИМЫЕ для работы скрипта колонки НЕ найдены в загруженном all_stocks_df: {set(missing_required_cols_in_loaded_df)}\")\n",
    "        print(\"Это может означать, что CSV файлы не содержат всех нужных признаков или целевых переменных, либо есть опечатки в именах.\")\n",
    "        print(\"Пожалуйста, проверьте ваши CSV файлы и определения колонок в Ячейке 3.\")\n",
    "        if 'NetDebt_EBITDA_y_y' in missing_required_cols_in_loaded_df:\n",
    "            print(\"-> Среди отсутствующих есть 'NetDebt_EBITDA_y_y'. Это важный базовый признак. Проверьте его наличие и название в CSV.\")\n",
    "    else:\n",
    "        print(\"\\nВсе НЕОБХОДИМЫЕ для обучения колонки (идентификаторы, признаки, актуальные таргеты) присутствуют в all_stocks_df.\")\n",
    "else:\n",
    "    print(\"\\nПроверка необходимых колонок не проводилась, так как all_stocks_df пуст (данные еще не загружены или не найдены).\")\n",
    "\n",
    "print(\"\\nСписки признаков (включая новые сценарии X_TECH_MACRO, X_TECH_ONLY) и целевых переменных определены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательная функция для метрики Sgn Acc\n",
    "\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Рассчитывает точность предсказания знака.\n",
    "    1, если знаки совпадают (или оба 0), 0 иначе.\n",
    "    \"\"\"\n",
    "    y_true_sign = np.sign(y_true)\n",
    "    y_pred_sign = np.sign(y_pred)\n",
    "    return np.mean(y_true_sign == y_pred_sign)\n",
    "\n",
    "print(\"Функция sign_accuracy определена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(df, ticker_name, target_col, model_type, feature_set_name, current_feature_list, random_state=42):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модель на ЗАДАННОМ списке признаков.\n",
    "    Обрабатывает NaN в целевой переменной.\n",
    "    Использует TimeSeriesSplit для разделения данных (или последние 15% для теста, если данных мало).\n",
    "    Не заполняет NaN в признаках (LightGBM, XGBoost и CatBoost обработают их).\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'Ticker': ticker_name,\n",
    "        'TargetVariable': target_col,\n",
    "        'ModelType': model_type,\n",
    "        'FeatureSet': feature_set_name,\n",
    "        'NumTrainSamples': 0,\n",
    "        'NumTestSamples': 0,\n",
    "        'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'Sgn_acc': np.nan,\n",
    "        'Accuracy': np.nan, 'Precision': np.nan, 'Recall': np.nan, 'F1': np.nan, 'ROC_AUC': np.nan\n",
    "    }\n",
    "\n",
    "    final_feature_list_for_df = [f for f in current_feature_list if f in df.columns]\n",
    "    \n",
    "    if len(final_feature_list_for_df) < len(current_feature_list):\n",
    "        missing_from_list = set(current_feature_list) - set(final_feature_list_for_df)\n",
    "        print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: \\\\\\n              Некоторые признаки из заданного списка {feature_set_name} отсутствуют в DataFrame: {missing_from_list}.\\\\\\n              Будут использованы только доступные: {len(final_feature_list_for_df)} из {len(current_feature_list)}.\")\n",
    "\n",
    "    if not final_feature_list_for_df:\n",
    "        print(f\"КРИТИЧЕСКОЕ ПРЕДУПРЕЖДЕНИЕ для {ticker_name}, таргет {target_col}, набор {feature_set_name}: \\\\\\n              Ни один из признаков из списка {feature_set_name} не найден в DataFrame. Пропуск этого сценария.\")\n",
    "        results['MAE'] = 'NoFeaturesInDf' if model_type.endswith('Regressor') else np.nan\n",
    "        results['Accuracy'] = 'NoFeaturesInDf' if model_type.endswith('Classifier') else np.nan\n",
    "        return results\n",
    "\n",
    "    X = df[final_feature_list_for_df].copy()\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    valid_indices = y.dropna().index\n",
    "    X = X.loc[valid_indices]\n",
    "    y = y.loc[valid_indices]\n",
    "\n",
    "    if X.empty or y.empty or len(X) < 2: \n",
    "        print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: После удаления NaN в таргете не осталось данных или их слишком мало ({len(X)}).\")\n",
    "        results['MAE'] = 'NoData' if model_type.endswith('Regressor') else np.nan\n",
    "        results['Accuracy'] = 'NoData' if model_type.endswith('Classifier') else np.nan\n",
    "        return results\n",
    "\n",
    "    if X.shape[1] == 0:\n",
    "        print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: Не осталось признаков после обработки NaN в таргете.\")\n",
    "        results['MAE'] = 'NoFeaturesPostTargetNaN' if model_type.endswith('Regressor') else np.nan\n",
    "        results['Accuracy'] = 'NoFeaturesPostTargetNaN' if model_type.endswith('Classifier') else np.nan\n",
    "        return results\n",
    "\n",
    "    n_splits_for_ts = 5 \n",
    "    min_samples_for_tscv = n_splits_for_ts + 1\n",
    "\n",
    "    if len(X) < min_samples_for_tscv:\n",
    "        print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: Слишком мало данных ({len(X)}) для TimeSeriesSplit. Используем простой split (~15% тест).\" )\n",
    "        test_sample_size = int(len(X) * 0.15)\n",
    "        if test_sample_size == 0 and len(X) > 1: test_sample_size = 1\n",
    "        if len(X) - test_sample_size < 1 or test_sample_size < 1:\n",
    "            print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: Недостаточно данных для простого разделения.\")\n",
    "            results['MAE'] = 'NoTrainTestData' if model_type.endswith('Regressor') else np.nan\n",
    "            results['Accuracy'] = 'NoTrainTestData' if model_type.endswith('Classifier') else np.nan\n",
    "            return results\n",
    "        train_indices = X.index[:len(X)-test_sample_size]\n",
    "        test_indices = X.index[len(X)-test_sample_size:]\n",
    "    else:\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits_for_ts)\n",
    "        all_splits = list(tscv.split(X, y))\n",
    "        train_indices, test_indices = all_splits[-1] \n",
    "        \n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    results['NumTrainSamples'] = len(X_train)\n",
    "    results['NumTestSamples'] = len(X_test)\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"Предупреждение для {ticker_name}, таргет {target_col}, набор {feature_set_name}: Пустой train или test набор.\")\n",
    "        results['MAE'] = 'NoTrainTestData' if model_type.endswith('Regressor') else np.nan\n",
    "        results['Accuracy'] = 'NoTrainTestData' if model_type.endswith('Classifier') else np.nan\n",
    "        return results\n",
    "\n",
    "    model = None\n",
    "    is_regressor = False\n",
    "    if model_type == 'LGBMRegressor':\n",
    "        model = LGBMRegressor(random_state=random_state, verbosity=-1)\n",
    "        is_regressor = True\n",
    "    elif model_type == 'XGBRegressor':\n",
    "        model = XGBRegressor(random_state=random_state)\n",
    "        is_regressor = True\n",
    "    elif model_type == 'LGBMClassifier':\n",
    "        model = LGBMClassifier(random_state=random_state, verbosity=-1)\n",
    "    elif model_type == 'XGBClassifier':\n",
    "        model = XGBClassifier(random_state=random_state, eval_metric='logloss' if pd.unique(y_train).size <= 2 else None)\n",
    "    elif model_type == 'CatBoostRegressor':\n",
    "        model = CatBoostRegressor(random_state=random_state, verbose=0)\n",
    "        is_regressor = True\n",
    "    elif model_type == 'CatBoostClassifier':\n",
    "        model = CatBoostClassifier(random_state=random_state, verbose=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип модели: {model_type}\")\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if is_regressor:\n",
    "            results['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "            results['RMSE'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            results['R2'] = r2_score(y_test, y_pred)\n",
    "            results['Sgn_acc'] = sign_accuracy(y_test, y_pred)\n",
    "        else: \n",
    "            results['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "            results['Precision'] = precision_score(y_test, y_pred, zero_division=0)\n",
    "            results['Recall'] = recall_score(y_test, y_pred, zero_division=0)\n",
    "            results['F1'] = f1_score(y_test, y_pred, zero_division=0)\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                if len(np.unique(y_test)) <= 2:\n",
    "                    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                    results['ROC_AUC'] = roc_auc_score(y_test, y_pred_proba)\n",
    "                else: \n",
    "                    results['ROC_AUC'] = np.nan\n",
    "            else: \n",
    "                results['ROC_AUC'] = np.nan\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обучении/оценке модели {model_type} для {ticker_name}, таргет {target_col}, набор {feature_set_name}: {e}\")\n",
    "        error_msg_short = str(e).splitlines()[0][:70] \n",
    "        if is_regressor: results['MAE'] = f'Error: {error_msg_short}'\n",
    "        else: results['Accuracy'] = f'Error: {error_msg_short}'\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Функция train_evaluate_model обновлена для обработки NaN в TabM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск цикла исследования\n",
    "\n",
    "all_results_list = []\n",
    "\n",
    "dataframes_to_process = {}\n",
    "if not sber_df.empty: dataframes_to_process['SBER'] = sber_df\n",
    "if not rosn_df.empty: dataframes_to_process['ROSN'] = rosn_df\n",
    "if not all_stocks_df.empty: dataframes_to_process['ALL_STOCKS'] = all_stocks_df\n",
    "else: print(\"Нет данных для обработки в sber_df, rosn_df или all_stocks_df.\")\n",
    "\n",
    "model_types_reg = ['LGBMRegressor', 'XGBRegressor']\n",
    "model_types_clf = ['LGBMClassifier', 'XGBClassifier']\n",
    "\n",
    "# Определяем словарь с наборами признаков для итерации\n",
    "# Ключ - имя набора (для отчета), Значение - список признаков\n",
    "feature_set_scenarios = {\n",
    "    \"Base\": X_base_features,\n",
    "    \"Extended\": X_extended_features,\n",
    "    \"Tech_Macro\": X_TECH_MACRO_features,\n",
    "    \"Tech_Only\": X_TECH_ONLY_features\n",
    "}\n",
    "\n",
    "if not dataframes_to_process:\n",
    "    print(\"Нет датафреймов для обработки. Проверьте загрузку данных.\")\n",
    "else:\n",
    "    print(f\"Начинаем исследование для: {list(dataframes_to_process.keys())}\")\n",
    "    print(f\"Будут протестированы следующие наборы признаков: {list(feature_set_scenarios.keys())}\\n\")\n",
    "\n",
    "    for df_name, current_df in dataframes_to_process.items():\n",
    "        print(f\"--- Обработка датафрейма: {df_name} ---\")\n",
    "        \n",
    "        for target in y_reg_targets:\n",
    "            if target not in current_df.columns:\n",
    "                print(f\"Целевая переменная {target} отсутствует в {df_name}. Пропуск.\")\n",
    "                continue\n",
    "            for model_name in model_types_reg:\n",
    "                for f_set_name, f_set_list in feature_set_scenarios.items(): # Итерация по словарю наборов признаков\n",
    "                    print(f\"Обучение (Регрессия): {model_name} на {f_set_name} ({len(f_set_list)} признаков) для {target} ({df_name})\")\n",
    "                    results = train_evaluate_model(current_df, df_name, target, model_name, \n",
    "                                                   f_set_name, # Имя набора для отчета\n",
    "                                                   f_set_list  # Список признаков для этого набора\n",
    "                                                  )\n",
    "                    all_results_list.append(results)\n",
    "                    # Выводим одну из ключевых метрик для быстрой проверки\n",
    "                    print(f\"  Результат: MAE={results.get('MAE', 'N/A')}, RMSE={results.get('RMSE', 'N/A')}, R2={results.get('R2', 'N/A')}, Sgn_acc={results.get('Sgn_acc', 'N/A')}\")\n",
    "\n",
    "        for target in y_clf_binary_targets:\n",
    "            if target not in current_df.columns:\n",
    "                print(f\"Целевая переменная {target} отсутствует в {df_name}. Пропуск.\")\n",
    "                continue\n",
    "            for model_name in model_types_clf:\n",
    "                for f_set_name, f_set_list in feature_set_scenarios.items(): # Итерация по словарю наборов признаков\n",
    "                    print(f\"Обучение (Классификация): {model_name} на {f_set_name} ({len(f_set_list)} признаков) для {target} ({df_name})\")\n",
    "                    results = train_evaluate_model(current_df, df_name, target, model_name, \n",
    "                                                   f_set_name, # Имя набора для отчета\n",
    "                                                   f_set_list  # Список признаков для этого набора\n",
    "                                                  )\n",
    "                    all_results_list.append(results)\n",
    "                    # Выводим одну из ключевых метрик для быстрой проверки\n",
    "                    print(f\"  Результат: Acc={results.get('Accuracy', 'N/A')}, F1={results.get('F1', 'N/A')}, ROC_AUC={results.get('ROC_AUC', 'N/A')}\")\n",
    "        print(f\"--- Обработка датафрейма {df_name} завершена ---\\n\")\n",
    "\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    print(\"\\n--- Исследование завершено. Итоговая таблица результатов: ---\")\n",
    "    # Убедимся, что все нужные колонки есть перед выводом, или выведем все, что есть\n",
    "    cols_to_show = ['Ticker', 'TargetVariable', 'ModelType', 'FeatureSet', 'NumTrainSamples', 'NumTestSamples', \n",
    "                    'MAE', 'RMSE', 'R2', 'Sgn_acc', \n",
    "                    'Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC']\n",
    "    existing_cols_in_results = [col for col in cols_to_show if col in results_df.columns]\n",
    "    print(results_df[existing_cols_in_results].head())\n",
    "    \n",
    "    results_filename = \"market_genius_model_results_v2.csv\" # Новое имя файла для новых результатов\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "    print(f\"\\nРезультаты сохранены в файл: {results_filename}\")\n",
    "\n",
    "    if not results_df.empty:\n",
    "        print(\"\\nДетали по последним нескольким записям:\")\n",
    "        print(results_df[existing_cols_in_results].tail())\n",
    "\n",
    "print(\"\\nСкрипт завершил выполнение.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка результатов\n",
    "results_file = '../market_genius_model_results_v2.csv'\n",
    "try:\n",
    "    df_results = pd.read_csv(results_file)\n",
    "    print(f\"Файл '{results_file}' успешно загружен. Форма: {df_results.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ОШИБКА: Файл '{results_file}' не найден. Пожалуйста, убедитесь, что он находится в той же директории, что и ноутбук, или укажите правильный путь.\")\n",
    "    df_results = pd.DataFrame() # Создаем пустой DataFrame, чтобы избежать ошибок ниже\n",
    "\n",
    "if not df_results.empty:\n",
    "    # Преобразуем строковые значения ошибок/пропусков в метриках в NaN\n",
    "    metric_cols = ['MAE', 'RMSE', 'R2', 'Sgn_acc', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC']\n",
    "    for col in metric_cols:\n",
    "        if col in df_results.columns:\n",
    "            df_results[col] = pd.to_numeric(df_results[col], errors='coerce')\n",
    "\n",
    "    print(\"\\nПервые 5 строк загруженных результатов:\")\n",
    "    print(df_results.head())\n",
    "\n",
    "    print(\"\\nТипы данных в df_results:\")\n",
    "    df_results.info()\n",
    "\n",
    "    # --- Быстрый взгляд на производительность по отдельным тикерам (SBER, ROSN) ---\n",
    "    df_individual_tickers = df_results[df_results['Ticker'].isin(['SBER', 'ROSN'])]\n",
    "    \n",
    "    if not df_individual_tickers.empty:\n",
    "        print(\"\\n--- Средние метрики для ИНДИВИДУАЛЬНЫХ тикеров (SBER, ROSN) ---\")\n",
    "        \n",
    "        # Регрессия для индивидуальных\n",
    "        df_individual_reg = df_individual_tickers[df_individual_tickers['ModelType'].str.contains('Regressor')]\n",
    "        if not df_individual_reg.empty:\n",
    "            print(\"\\nРегрессия (средние MAE, R2, Sgn_acc):\")\n",
    "            print(df_individual_reg.groupby(['Ticker', 'TargetVariable'])[['MAE', 'R2', 'Sgn_acc']].mean())\n",
    "        else:\n",
    "            print(\"\\nНет данных по регрессии для индивидуальных тикеров.\")\n",
    "\n",
    "        # Классификация для индивидуальных\n",
    "        df_individual_clf = df_individual_tickers[df_individual_tickers['ModelType'].str.contains('Classifier')]\n",
    "        if not df_individual_clf.empty:\n",
    "            print(\"\\nКлассификация (средние F1, ROC_AUC):\")\n",
    "            # Для Precision, Recall, F1 часто бывают нули, особенно если один из классов не предсказан.\n",
    "            # ROC_AUC может быть более стабильной метрикой для усреднения, если нет проблем с дисбалансом.\n",
    "            print(df_individual_clf.groupby(['Ticker', 'TargetVariable'])[['F1', 'ROC_AUC', 'Accuracy']].mean())\n",
    "        else:\n",
    "            print(\"\\nНет данных по классификации для индивидуальных тикеров.\")\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"\\nНе найдено результатов для тикеров SBER или ROSN для отдельного анализа.\")\n",
    "\n",
    "    # --- Фокус на ALL_STOCKS ---\n",
    "    df_all_stocks = df_results[df_results['Ticker'] == 'ALL_STOCKS'].copy() # Используем .copy() для избежания SettingWithCopyWarning\n",
    "    \n",
    "    if not df_all_stocks.empty:\n",
    "        print(\"\\n--- Анализ для ALL_STOCKS ---\")\n",
    "        print(f\"Количество записей для ALL_STOCKS: {df_all_stocks.shape[0]}\")\n",
    "\n",
    "        # Разделим на регрессионные и классификационные для ALL_STOCKS\n",
    "        df_all_stocks_reg = df_all_stocks[df_all_stocks['ModelType'].str.contains('Regressor')].copy()\n",
    "        df_all_stocks_clf = df_all_stocks[df_all_stocks['ModelType'].str.contains('Classifier')].copy()\n",
    "\n",
    "        # 1. Регрессионные модели для ALL_STOCKS\n",
    "        if not df_all_stocks_reg.empty:\n",
    "            print(\"\\n1. Регрессионные модели для ALL_STOCKS:\")\n",
    "            print(\"Средние R2 и Sgn_acc по TargetVariable, FeatureSet, ModelType:\")\n",
    "            agg_reg_metrics = df_all_stocks_reg.groupby(['TargetVariable', 'FeatureSet', 'ModelType'])[['R2', 'Sgn_acc']].mean().sort_values(by=['TargetVariable', 'Sgn_acc'], ascending=[True, False])\n",
    "            print(agg_reg_metrics)\n",
    "            \n",
    "            # Визуализация Sgn_acc для регрессии на ALL_STOCKS\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            sns.barplot(data=df_all_stocks_reg, x='TargetVariable', y='Sgn_acc', hue='FeatureSet', palette='viridis')\n",
    "            plt.title('Sgn Accuracy для Регрессионных моделей (ALL_STOCKS) по FeatureSet')\n",
    "            plt.ylabel('Средняя Sgn Accuracy')\n",
    "            plt.xlabel('Целевая переменная (Регрессия)')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.legend(title='Набор признаков', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            sns.barplot(data=df_all_stocks_reg, x='TargetVariable', y='R2', hue='FeatureSet', palette='viridis')\n",
    "            plt.title('R2 для Регрессионных моделей (ALL_STOCKS) по FeatureSet')\n",
    "            plt.ylabel('Средний R2')\n",
    "            plt.xlabel('Целевая переменная (Регрессия)')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.axhline(0, color='red', linestyle='--', label='R2 = 0')\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.legend(title='Набор признаков', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(\"Нет данных по регрессионным моделям для ALL_STOCKS.\")\n",
    "\n",
    "        # 2. Классификационные модели для ALL_STOCKS (как вы отметили, они более успешны)\n",
    "        if not df_all_stocks_clf.empty:\n",
    "            print(\"\\n2. Классификационные модели для ALL_STOCKS:\")\n",
    "            # Сортируем по F1 или ROC_AUC для лучшего обзора\n",
    "            clf_metrics_summary = df_all_stocks_clf.groupby(['TargetVariable', 'FeatureSet', 'ModelType'])[['Accuracy', 'F1', 'ROC_AUC', 'Precision', 'Recall']].mean().sort_values(by=['TargetVariable', 'ROC_AUC'], ascending=[True, False])\n",
    "            print(\"Сводка метрик классификации (средние) для ALL_STOCKS:\")\n",
    "            with pd.option_context('display.max_rows', None): # Показать все строки для этой таблицы\n",
    "                 print(clf_metrics_summary)\n",
    "\n",
    "            # Визуализация для классификации (например, ROC AUC)\n",
    "            primary_metric_clf = 'ROC_AUC' # Можно изменить на 'F1' или 'Accuracy'\n",
    "            \n",
    "            plt.figure(figsize=(18, 8)) # Увеличим размер для лучшей читаемости\n",
    "            sns.catplot(data=df_all_stocks_clf, x='TargetVariable', y=primary_metric_clf, hue='FeatureSet', col='ModelType', kind='bar', palette='mako', height=6, aspect=1.2)\n",
    "            # plt.suptitle(f'{primary_metric_clf} для Классификационных моделей (ALL_STOCKS)', y=1.03, fontsize=16) # catplot сам создает figure-level title\n",
    "            # Общие настройки для всех subplots в catplot\n",
    "            for ax in plt.gcf().axes: # plt.gcf() получает текущую фигуру\n",
    "                 ax.tick_params(axis='x', rotation=45)\n",
    "                 ax.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.97]) # rect для предотвращения перекрытия с suptitle (если бы он был)\n",
    "            plt.show()\n",
    "\n",
    "            # Сравнение Base vs Extended для классификации\n",
    "            print(f\"\\nСравнение влияния медиа-признаков ({primary_metric_clf}): Base vs Extended (Классификация ALL_STOCKS)\")\n",
    "            df_base_ext_clf = df_all_stocks_clf[df_all_stocks_clf['FeatureSet'].isin(['Base', 'Extended'])]\n",
    "            \n",
    "            if not df_base_ext_clf.empty:\n",
    "                try:\n",
    "                    # pivot_table может вызвать ошибку, если есть NaN в index/columns/values после фильтрации\n",
    "                    pivot_base_ext = df_base_ext_clf.pivot_table(index=['TargetVariable', 'ModelType'], \n",
    "                                                                columns='FeatureSet', \n",
    "                                                                values=primary_metric_clf)\n",
    "                    if 'Base' in pivot_base_ext.columns and 'Extended' in pivot_base_ext.columns:\n",
    "                        pivot_base_ext['Improvement_Extended_vs_Base'] = ((pivot_base_ext['Extended'] - pivot_base_ext['Base']) / pivot_base_ext['Base']) * 100\n",
    "                        print(pivot_base_ext[[primary_metric_clf, 'Improvement_Extended_vs_Base']].sort_values(by='Improvement_Extended_vs_Base', ascending=False))\n",
    "                    else:\n",
    "                        print(\"Не удалось создать pivot table: отсутствуют колонки 'Base' или 'Extended' после фильтрации.\")\n",
    "                        print(pivot_base_ext)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка при создании pivot_table для Base vs Extended: {e}\")\n",
    "            else:\n",
    "                 print(\"Нет данных для сравнения Base vs Extended (классификация).\")\n",
    "\n",
    "\n",
    "            # Сравнение влияния удаления фундаментальных и макро признаков\n",
    "            print(f\"\\nСравнение влияния различных наборов признаков ({primary_metric_clf}) (Классификация ALL_STOCKS)\")\n",
    "            # Tech_Macro vs Base\n",
    "            # Tech_Only vs Tech_Macro\n",
    "            \n",
    "            # Для упрощения выведем таблицу сгруппированную по TargetVariable, ModelType, показывающую метрику для каждого FeatureSet\n",
    "            pivot_all_features_clf = df_all_stocks_clf.pivot_table(index=['TargetVariable', 'ModelType'],\n",
    "                                                                   columns='FeatureSet',\n",
    "                                                                   values=primary_metric_clf)\n",
    "            # Переупорядочим колонки для логичного сравнения\n",
    "            ordered_feature_sets = [fs for fs in ['Base', 'Extended', 'Tech_Macro', 'Tech_Only'] if fs in pivot_all_features_clf.columns]\n",
    "            print(pivot_all_features_clf[ordered_feature_sets])\n",
    "            \n",
    "        else:\n",
    "            print(\"Нет данных по классификационным моделям для ALL_STOCKS.\")\n",
    "    else:\n",
    "        print(\"Нет данных для ALL_STOCKS.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame с результатами пуст. Анализ невозможен.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Подбор гиперпараметров для LGBMClassifier на ALL_STOCKS (X_extended_features) с использованием Optuna ---\n",
    "\n",
    "# 1. Подготовка данных\n",
    "target_clf_for_tuning = 'target_1d_binary' \n",
    "features_for_tuning = X_extended_features\n",
    "\n",
    "if not all_stocks_df.empty and target_clf_for_tuning in all_stocks_df.columns:\n",
    "    df_for_tuning = all_stocks_df.copy()\n",
    "\n",
    "    # Убедимся, что все выбранные признаки существуют в df_for_tuning\n",
    "    actual_features_for_tuning = [f for f in features_for_tuning if f in df_for_tuning.columns]\n",
    "    if len(actual_features_for_tuning) < len(features_for_tuning):\n",
    "        missing_features = set(features_for_tuning) - set(actual_features_for_tuning)\n",
    "        print(f\"Предупреждение: Следующие признаки из X_extended_features отсутствуют в all_stocks_df и не будут использованы: {missing_features}\")\n",
    "\n",
    "    if not actual_features_for_tuning:\n",
    "        print(\"КРИТИЧЕСКОЕ ПРЕДУПРЕЖДЕНИЕ: Ни один из признаков X_extended_features не найден в all_stocks_df. Подбор гиперпараметров невозможен.\")\n",
    "    else:\n",
    "        X_tune = df_for_tuning[actual_features_for_tuning]\n",
    "        y_tune = df_for_tuning[target_clf_for_tuning]\n",
    "\n",
    "        # Удаление строк с NaN в целевой переменной\n",
    "        valid_indices_tune = y_tune.dropna().index\n",
    "        X_tune = X_tune.loc[valid_indices_tune]\n",
    "        y_tune = y_tune.loc[valid_indices_tune]\n",
    "\n",
    "        if X_tune.empty or y_tune.empty or len(X_tune) < 20: # Увеличил минимальный порог для Optuna и TimeSeriesSplit\n",
    "            print(f\"Недостаточно данных (строк: {len(X_tune)}) после обработки NaN в таргете для подбора гиперпараметров. Требуется как минимум 20.\")\n",
    "        else:\n",
    "            print(f\"Данные для подбора гиперпараметров LGBMClassifier подготовлены. X_tune: {X_tune.shape}, y_tune: {y_tune.shape}\")\n",
    "            print(f\"Целевая переменная: {target_clf_for_tuning}\")\n",
    "            print(f\"Количество используемых признаков: {len(actual_features_for_tuning)}\")\n",
    "\n",
    "            # 2. Определение функции objective для Optuna\n",
    "            def objective(trial):\n",
    "                # Определяем пространства поиска гиперпараметров\n",
    "                params = {\n",
    "                    'objective': 'binary',\n",
    "                    'metric': 'auc',\n",
    "                    'verbosity': -1,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "                    'num_leaves': trial.suggest_int('num_leaves', 20, 100, step=5),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                    'min_child_samples': trial.suggest_int('min_child_samples', 5, 50, step=5),\n",
    "                    'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.1),\n",
    "                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.1),\n",
    "                    'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True), # L1 regularization\n",
    "                    'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True), # L2 regularization\n",
    "                    'random_state': 42,\n",
    "                    'n_jobs': -1\n",
    "                }\n",
    "\n",
    "                # Кросс-валидация с TimeSeriesSplit\n",
    "                # Убедимся, что данных достаточно для n_splits\n",
    "                n_splits_cv = 5\n",
    "                if len(X_tune) < n_splits_cv + 1 :\n",
    "                    print(f\"Данных ({len(X_tune)}) недостаточно для {n_splits_cv} фолдов TimeSeriesSplit. Уменьшаю n_splits до максимально возможного.\")\n",
    "                    n_splits_cv = max(2, len(X_tune) // 2) # хотя бы 2 фолда, если возможно\n",
    "\n",
    "                tscv = TimeSeriesSplit(n_splits=n_splits_cv)\n",
    "                roc_auc_scores = []\n",
    "\n",
    "                for train_index, val_index in tscv.split(X_tune, y_tune):\n",
    "                    X_train_fold, X_val_fold = X_tune.iloc[train_index], X_tune.iloc[val_index]\n",
    "                    y_train_fold, y_val_fold = y_tune.iloc[train_index], y_tune.iloc[val_index]\n",
    "\n",
    "                    if len(X_train_fold) == 0 or len(X_val_fold) == 0:\n",
    "                        # print(\"Пропуск фолда из-за пустого train/validation набора.\")\n",
    "                        continue\n",
    "                    if len(np.unique(y_train_fold)) < 2 or len(np.unique(y_val_fold)) < 2:\n",
    "                        # print(\"Пропуск фолда из-за одного класса в y_train_fold или y_val_fold\")\n",
    "                        continue # Пропускаем фолд, если в нем только один класс\n",
    "\n",
    "                    model = LGBMClassifier(**params)\n",
    "                    try:\n",
    "                        model.fit(X_train_fold, y_train_fold,\n",
    "                                    eval_set=[(X_val_fold, y_val_fold)],\n",
    "                                    eval_metric='auc',\n",
    "                                    callbacks=[optuna.integration.LightGBMPruningCallback(trial, 'auc')])\n",
    "\n",
    "                        preds_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                        roc_auc_scores.append(roc_auc_score(y_val_fold, preds_proba))\n",
    "                    except Exception as e:\n",
    "                        # print(f\"Ошибка во время обучения или предсказания на фолде: {e}\")\n",
    "                        roc_auc_scores.append(0.0) # или np.nan, но Optuna ожидает float\n",
    "\n",
    "                return np.mean(roc_auc_scores) if roc_auc_scores else 0.0\n",
    "\n",
    "            # 3. Запуск оптимизации Optuna\n",
    "            study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
    "            print(f\"Начинаем подбор гиперпараметров (Optuna)...\")\n",
    "            study.optimize(objective, n_trials=50, timeout=1800) # 50 попыток или 30 минут\n",
    "\n",
    "            print(\"\\\\n--- Результаты подбора гиперпараметров Optuna ---\")\n",
    "            print(f\"Лучшее значение ROC AUC на кросс-валидации: {study.best_value:.4f}\")\n",
    "            print(\"Лучшие гиперпараметры:\")\n",
    "            best_lgbm_params = study.best_params\n",
    "            for key, value in best_lgbm_params.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "            # Дополняем параметры, не участвовавшие в подборе\n",
    "            best_lgbm_params['objective'] = 'binary'\n",
    "            best_lgbm_params['metric'] = 'auc'\n",
    "            best_lgbm_params['verbosity'] = -1\n",
    "            best_lgbm_params['random_state'] = 42\n",
    "            best_lgbm_params['n_jobs'] = -1\n",
    "\n",
    "            # 4. Обучение и оценка лучшей модели LGBMClassifier на последнем фолде TimeSeriesSplit\n",
    "            print(\"\\\\n--- Обучение и оценка LGBMClassifier с лучшими гиперпараметрами на тестовом наборе ---\")\n",
    "\n",
    "            final_tscv_eval = TimeSeriesSplit(n_splits=5)\n",
    "            all_final_splits_eval = list(final_tscv_eval.split(X_tune, y_tune))\n",
    "            train_final_idx_eval, test_final_idx_eval = all_final_splits_eval[-1]\n",
    "\n",
    "            X_train_final_eval, X_test_final_eval = X_tune.iloc[train_final_idx_eval], X_tune.iloc[test_final_idx_eval]\n",
    "            y_train_final_eval, y_test_final_eval = y_tune.iloc[train_final_idx_eval], y_tune.iloc[test_final_idx_eval]\n",
    "\n",
    "            if len(X_train_final_eval) == 0 or len(X_test_final_eval) == 0:\n",
    "                print(\"Ошибка: Пустой train или test набор для финальной оценки.\")\n",
    "            elif len(np.unique(y_train_final_eval)) < 2 or len(np.unique(y_test_final_eval)) < 2:\n",
    "                print(\"Ошибка: Один класс в y_train_final_eval или y_test_final_eval для финальной оценки.\")\n",
    "            else:\n",
    "                print(f\"Размер финального обучающего набора: {X_train_final_eval.shape}, тестового: {X_test_final_eval.shape}\")\n",
    "\n",
    "                final_lgbm_model = LGBMClassifier(**best_lgbm_params)\n",
    "                final_lgbm_model.fit(X_train_final_eval, y_train_final_eval)\n",
    "                y_pred_final_eval = final_lgbm_model.predict(X_test_final_eval)\n",
    "                y_pred_proba_final_eval = final_lgbm_model.predict_proba(X_test_final_eval)[:, 1]\n",
    "\n",
    "                print(\"Метрики на тестовом наборе с лучшими гиперпараметрами:\")\n",
    "                print(f\"  Accuracy: {accuracy_score(y_test_final_eval, y_pred_final_eval):.4f}\")\n",
    "                print(f\"  Precision: {precision_score(y_test_final_eval, y_pred_final_eval, zero_division=0):.4f}\")\n",
    "                print(f\"  Recall: {recall_score(y_test_final_eval, y_pred_final_eval, zero_division=0):.4f}\")\n",
    "                print(f\"  F1 Score: {f1_score(y_test_final_eval, y_pred_final_eval, zero_division=0):.4f}\")\n",
    "                print(f\"  ROC AUC: {roc_auc_score(y_test_final_eval, y_pred_proba_final_eval):.4f}\")\n",
    "\n",
    "                # Отображение важности признаков для лучшей модели\n",
    "                # import matplotlib.pyplot as plt\n",
    "                # import seaborn as sns\n",
    "                # print(\"\\\\nОтображение важности признаков...\")\n",
    "                # feature_importances = pd.Series(final_lgbm_model.feature_importances_, index=X_tune.columns)\n",
    "                # plt.figure(figsize=(10, max(10, len(X_tune.columns)//4))) # Динамический размер для большого кол-ва признаков\n",
    "                # sns.barplot(x=feature_importances.sort_values(ascending=False).head(30),\n",
    "                #             y=feature_importances.sort_values(ascending=False).head(30).index)\n",
    "                # plt.title('Топ-30 Важных признаков (LGBMClassifier с Optuna)')\n",
    "                # plt.xlabel('Важность')\n",
    "                # plt.ylabel('Признак')\n",
    "                # plt.tight_layout()\n",
    "                # plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Не удалось загрузить all_stocks_df или отсутствует целевая колонка для подбора гиперпараметров.\")\n",
    "\n",
    "print(\"\\\\nПодбор гиперпараметров завершен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(final_lgbm_model.feature_importances_, index=X_tune.columns)\n",
    "plt.figure(figsize=(10, max(10, len(X_tune.columns)//4))) # Динамический размер для большого кол-ва признаков\n",
    "sns.barplot(x=feature_importances.sort_values(ascending=False).head(30),\n",
    "            y=feature_importances.sort_values(ascending=False).head(30).index)\n",
    "plt.title('Топ-30 Важных признаков (LGBMClassifier с Optuna)')\n",
    "plt.xlabel('Важность')\n",
    "plt.ylabel('Признак')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
