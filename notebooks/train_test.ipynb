{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') # Игнорируем предупреждения для чистоты вывода\n",
    "\n",
    "# Определим путь к данным\n",
    "# Убедитесь, что этот путь корректен относительно расположения вашего ноутбука\n",
    "try:\n",
    "    # Попытка использовать путь относительно папки notebooks/\n",
    "    data_path = '../data/processed/ready_for_training'\n",
    "    if not os.path.exists(os.path.join(data_path, 'YDEX_processed.csv')):\n",
    "         # Если не найдено, пробуем путь из корня проекта\n",
    "         data_path = 'data/processed/ready_for_training'\n",
    "         if not os.path.exists(os.path.join(data_path, 'YDEX_processed.csv')):\n",
    "             print(\"Не удалось автоматически определить путь к данным. Пожалуйста, укажите его вручную в переменной data_path.\")\n",
    "             data_path = input(\"Введите путь к папке ready_for_training: \") # Запрос пути у пользователя, если автоматически не найден\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при определении пути: {e}\")\n",
    "    data_path = 'data/processed/ready_for_training' # Значение по умолчанию\n",
    "\n",
    "tickers = ['YDEX', 'SBER', 'GAZP', 'DELI']\n",
    "datasets = {}\n",
    "\n",
    "print(f\"Используемый путь к данным: {data_path}\")\n",
    "\n",
    "# Загрузим данные\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(data_path, f'{ticker}_processed.csv')\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            datasets[ticker] = pd.read_csv(file_path, parse_dates=['DATE'], index_col='DATE')\n",
    "            # Сортируем данные по дате на всякий случай\n",
    "            datasets[ticker] = datasets[ticker].sort_index()\n",
    "            print(f\"Загружен {ticker}: {datasets[ticker].shape}\")\n",
    "        else:\n",
    "            print(f\"Файл для {ticker} не найден: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке {ticker}: {e}\")\n",
    "\n",
    "\n",
    "# Возьмем один датасет для примера определения колонок\n",
    "sample_ticker = None\n",
    "for t in tickers:\n",
    "    if t in datasets:\n",
    "        sample_ticker = t\n",
    "        break\n",
    "\n",
    "if sample_ticker and sample_ticker in datasets:\n",
    "    df_sample = datasets[sample_ticker]\n",
    "\n",
    "    # Определяем целевые колонки\n",
    "    target_columns = [col for col in df_sample.columns if 'target' in col]\n",
    "    print(f\"\\nЦелевые колонки ({len(target_columns)}): {target_columns}\")\n",
    "\n",
    "    # Определяем колонки признаков (все числовые, кроме целей и идентификаторов)\n",
    "    # Убедимся, что DATE и SECID не попали в признаки (DATE теперь индекс)\n",
    "    exclude_cols = target_columns + ['SECID']\n",
    "    feature_columns = [col for col in df_sample.select_dtypes(include=[np.number]).columns if col not in exclude_cols]\n",
    "    print(f\"Колонки признаков ({len(feature_columns)}): {feature_columns[:10]}...{feature_columns[-5:]}\") # Печатаем часть для краткости\n",
    "\n",
    "    # Проверим типы данных и наличие пропусков\n",
    "    print(f\"\\nИнформация о датасете (пример {sample_ticker}):\")\n",
    "    df_sample.info()\n",
    "    # Посчитаем % пропусков\n",
    "    missing_percentage = (df_sample[feature_columns + target_columns].isnull().sum() / len(df_sample) * 100).sort_values(ascending=False)\n",
    "    print(f\"\\nПроцент пропусков (топ-5, пример {sample_ticker}):\")\n",
    "    print(missing_percentage[missing_percentage > 0].head())\n",
    "\n",
    "    # Удалим строки, где есть пропуски в целевых переменных (без них обучение невозможно)\n",
    "    for ticker in datasets:\n",
    "        initial_rows = len(datasets[ticker])\n",
    "        datasets[ticker] = datasets[ticker].dropna(subset=target_columns)\n",
    "        removed_rows = initial_rows - len(datasets[ticker])\n",
    "        if removed_rows > 0:\n",
    "            print(f\"{ticker}: Удалено {removed_rows} строк с пропусками в target.\")\n",
    "\n",
    "else:\n",
    "    print(\"Не удалось загрузить ни один из указанных датасетов.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Хотя нам нужно временное разделение\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Импорты для LSTM добавим позже, когда будем его реализовывать\n",
    "\n",
    "# --- Параметры разделения ---\n",
    "TRAIN_SIZE = 0.70\n",
    "VALIDATION_SIZE = 0.15\n",
    "# TEST_SIZE будет 1.0 - TRAIN_SIZE - VALIDATION_SIZE = 0.15\n",
    "\n",
    "# --- Словари для хранения данных ---\n",
    "split_data = {} # Хранение разделенных и обработанных данных {ticker: {target: {'X_train': ..., 'y_train': ..., ...}}}\n",
    "scalers = {}    # Хранение обученных скейлеров {ticker: scaler}\n",
    "imputers = {}   # Хранение обученных импьютеров {ticker: imputer}\n",
    "\n",
    "# --- Цикл по тикерам для разделения и преобработки ---\n",
    "for ticker, df in datasets.items():\n",
    "    print(f\"\\nОбработка {ticker}...\")\n",
    "    if df.empty:\n",
    "        print(f\"Датасет для {ticker} пуст, пропуск.\")\n",
    "        continue\n",
    "\n",
    "    # Убедимся что feature_columns актуальны для текущего тикера (на случай разной структуры)\n",
    "    current_target_columns = [col for col in df.columns if 'target' in col]\n",
    "    current_exclude_cols = current_target_columns + ['SECID']\n",
    "    current_feature_columns = [col for col in df.select_dtypes(include=[np.number]).columns if col not in current_exclude_cols]\n",
    "\n",
    "    if not current_feature_columns:\n",
    "         print(f\"Не найдены числовые признаки для {ticker}, пропуск.\")\n",
    "         continue\n",
    "\n",
    "    X = df[current_feature_columns]\n",
    "    y = df[current_target_columns] # Пока берем все таргеты\n",
    "\n",
    "    # --- Временное разделение ---\n",
    "    n = len(df)\n",
    "    train_end_idx = int(n * TRAIN_SIZE)\n",
    "    validation_end_idx = int(n * (TRAIN_SIZE + VALIDATION_SIZE))\n",
    "\n",
    "    X_train = X.iloc[:train_end_idx]\n",
    "    X_val = X.iloc[train_end_idx:validation_end_idx]\n",
    "    X_test = X.iloc[validation_end_idx:]\n",
    "\n",
    "    y_train = y.iloc[:train_end_idx]\n",
    "    y_val = y.iloc[train_end_idx:validation_end_idx]\n",
    "    y_test = y.iloc[validation_end_idx:]\n",
    "\n",
    "    print(f\"  Размеры выборок для {ticker}: Train={len(X_train)}, Validation={len(X_val)}, Test={len(X_test)}\")\n",
    "\n",
    "    if len(X_train) == 0 or len(X_val) == 0 or len(X_test) == 0:\n",
    "        print(f\"  Недостаточно данных для разделения {ticker}, пропуск.\")\n",
    "        continue\n",
    "\n",
    "    # --- Обработка пропусков (Imputation) ---\n",
    "    # Заменяем бесконечные значения на NaN перед импутацией\n",
    "    X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_val.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "    imputers[ticker] = imputer # Сохраняем импьютер\n",
    "\n",
    "    # --- Масштабирование (Scaling) ---\n",
    "    scaler = StandardScaler()\n",
    "    # Обучаем скейлер только на обучающей выборке (уже без пропусков)\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imputed), columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(scaler.transform(X_val_imputed), columns=X_val.columns, index=X_val.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test_imputed), columns=X_test.columns, index=X_test.index)\n",
    "    scalers[ticker] = scaler # Сохраняем скейлер\n",
    "\n",
    "    # --- Сохранение данных для каждого таргета ---\n",
    "    split_data[ticker] = {}\n",
    "    for target_col in current_target_columns:\n",
    "        # Проверим наличие NaN в y после удаления строк на предыдущем шаге\n",
    "        if y_train[target_col].isnull().any() or y_val[target_col].isnull().any() or y_test[target_col].isnull().any():\n",
    "             print(f\"  Внимание: Найдены NaN в '{target_col}' для {ticker} ПОСЛЕ первоначальной очистки. Пропуск этого таргета.\")\n",
    "             continue\n",
    "\n",
    "        split_data[ticker][target_col] = {\n",
    "            'X_train': X_train_scaled, # Используем масштабированные и импутированные данные для большинства моделей\n",
    "            'y_train': y_train[target_col],\n",
    "            'X_val': X_val_scaled,\n",
    "            'y_val': y_val[target_col],\n",
    "            'X_test': X_test_scaled,\n",
    "            'y_test': y_test[target_col],\n",
    "            # Сохраним и немасштабированные (но с импутацией!) для моделей, которые этого не требуют (деревья)\n",
    "            'X_train_orig': X_train_imputed,\n",
    "            'X_val_orig': X_val_imputed,\n",
    "            'X_test_orig': X_test_imputed,\n",
    "        }\n",
    "    print(f\"  Данные для {ticker} разделены и предобработаны.\")\n",
    "\n",
    "# --- Определим модели (пока без LSTM) ---\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"XGBoost\": xgb.XGBRegressor(random_state=42, n_estimators=100, early_stopping_rounds=10), # n_estimators и early_stopping - пример\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42, n_estimators=100, learning_rate=0.1), # n_estimators и learning_rate - пример\n",
    "    \"CatBoost\": cb.CatBoostRegressor(random_state=42, iterations=100, verbose=0, early_stopping_rounds=10) # iterations и early_stopping - пример\n",
    "}\n",
    "\n",
    "# --- Словарь для хранения результатов ---\n",
    "results = {} # {ticker: {target: {model_name: {'metrics': {...}, 'predictions': ...}}}}\n",
    "\n",
    "print(\"\\nПодготовка завершена. Данные разделены и предобработаны.\")\n",
    "print(f\"Доступные тикеры для обучения: {list(split_data.keys())}\")\n",
    "if split_data:\n",
    "    # Найдем первый доступный тикер и таргет для примера\n",
    "    first_ticker = next(iter(split_data), None)\n",
    "    if first_ticker and split_data[first_ticker]:\n",
    "        first_target = next(iter(split_data[first_ticker]), None)\n",
    "        if first_target:\n",
    "             print(f\"Пример структуры split_data[{first_ticker}][{first_target}].keys(): {split_data[first_ticker][first_target].keys()}\")\n",
    "        else:\n",
    "             print(f\"Нет доступных таргетов для тикера {first_ticker}\")\n",
    "    else:\n",
    "         print(\"Нет доступных тикеров с данными.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import sqrt # Для RMSE\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Вычисляет набор метрик регрессии.\"\"\"\n",
    "    metrics = {}\n",
    "    metrics['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics['mse'] = mean_squared_error(y_true, y_pred)\n",
    "    metrics['rmse'] = sqrt(metrics['mse'])\n",
    "    metrics['r2'] = r2_score(y_true, y_pred)\n",
    "    # MAPE может вызвать ошибку, если y_true содержит нули\n",
    "    try:\n",
    "        # Заменяем нули в y_true на очень маленькое число, чтобы избежать деления на ноль\n",
    "        y_true_safe = np.where(y_true == 0, 1e-9, y_true)\n",
    "        metrics['mape'] = mean_absolute_percentage_error(y_true_safe, y_pred)\n",
    "    except Exception as e:\n",
    "        print(f\"  Предупреждение: Не удалось рассчитать MAPE: {e}\")\n",
    "        metrics['mape'] = np.nan\n",
    "    return metrics\n",
    "\n",
    "# --- Основной цикл обучения и оценки ---\n",
    "training_start_time = time.time()\n",
    "\n",
    "for ticker in split_data.keys():\n",
    "    print(f\"\\n===== Обучение для тикера: {ticker} =====\")\n",
    "    if ticker not in results:\n",
    "        results[ticker] = {}\n",
    "\n",
    "    for target_col in split_data[ticker].keys():\n",
    "        print(f\"  --- Таргет: {target_col} ---\")\n",
    "        if target_col not in results[ticker]:\n",
    "            results[ticker][target_col] = {}\n",
    "\n",
    "        # Извлекаем нужные данные для текущего таргета\n",
    "        data = split_data[ticker][target_col]\n",
    "        y_train = data['y_train']\n",
    "        y_val = data['y_val']\n",
    "        y_test = data['y_test']\n",
    "\n",
    "        # Проверка на случай, если y_val или y_test пустые (хотя не должно быть после проверок)\n",
    "        if y_val.empty or y_test.empty:\n",
    "            print(f\"    Пропуск таргета {target_col} для {ticker} из-за пустых y_val или y_test.\")\n",
    "            continue\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"    Модель: {model_name}\")\n",
    "            start_model_time = time.time()\n",
    "\n",
    "            # Выбираем данные (масштабированные или оригинальные)\n",
    "            if model_name == \"LinearRegression\":\n",
    "                X_train_fit = data['X_train']\n",
    "                X_val_fit = data['X_val']\n",
    "                X_test_predict = data['X_test']\n",
    "            else: # Для деревьев используем оригинальные (но импутированные)\n",
    "                X_train_fit = data['X_train_orig']\n",
    "                X_val_fit = data['X_val_orig']\n",
    "                X_test_predict = data['X_test_orig']\n",
    "\n",
    "            try:\n",
    "                # Обучение модели\n",
    "                if model_name == \"XGBoost\":\n",
    "                    model.fit(X_train_fit, y_train,\n",
    "                              eval_set=[(X_val_fit, y_val)],\n",
    "                              verbose=False)\n",
    "                elif model_name == \"LightGBM\":\n",
    "                    # LightGBM требует имя параметра early_stopping_rounds в fit\n",
    "                    callbacks = [lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "                    model.fit(X_train_fit, y_train,\n",
    "                              eval_set=[(X_val_fit, y_val)],\n",
    "                              callbacks=callbacks)\n",
    "                elif model_name == \"CatBoost\":\n",
    "                     # CatBoost имеет параметр early_stopping_rounds в конструкторе\n",
    "                     # но также может принимать eval_set в fit\n",
    "                     model.fit(X_train_fit, y_train,\n",
    "                               eval_set=[(X_val_fit, y_val)],\n",
    "                               verbose=0) # verbose=0 уже был в конструкторе, дублируем для ясности\n",
    "                else: # LinearRegression\n",
    "                    model.fit(X_train_fit, y_train)\n",
    "\n",
    "                # Предсказание\n",
    "                y_pred = model.predict(X_test_predict)\n",
    "\n",
    "                # Расчет метрик\n",
    "                metrics = calculate_metrics(y_test, y_pred)\n",
    "                results[ticker][target_col][model_name] = {\n",
    "                    'metrics': metrics,\n",
    "                    'predictions': pd.Series(y_pred, index=y_test.index) # Сохраняем предсказания с индексами\n",
    "                }\n",
    "                print(f\"      MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R2: {metrics['r2']:.4f}, MAPE: {metrics['mape']:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Ошибка при обучении/оценке модели {model_name} для {ticker}-{target_col}: {e}\")\n",
    "                results[ticker][target_col][model_name] = {'metrics': {}, 'predictions': None, 'error': str(e)}\n",
    "\n",
    "            end_model_time = time.time()\n",
    "            print(f\"      Время: {end_model_time - start_model_time:.2f} сек.\")\n",
    "\n",
    "\n",
    "training_end_time = time.time()\n",
    "print(f\"\\n===== Обучение завершено! Общее время: {training_end_time - training_start_time:.2f} сек. =====\")\n",
    "\n",
    "# Выведем пример структуры результатов\n",
    "if results:\n",
    "    first_ticker = next(iter(results))\n",
    "    if results[first_ticker]:\n",
    "        first_target = next(iter(results[first_ticker]))\n",
    "        if results[first_ticker][first_target]:\n",
    "            first_model = next(iter(results[first_ticker][first_target]))\n",
    "            print(f\"\\nПример структуры results[{first_ticker}][{first_target}][{first_model}]:\")\n",
    "            print(results[first_ticker][first_target][first_model]['metrics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Сбор метрик в DataFrame ---\n",
    "all_metrics_data = []\n",
    "\n",
    "for ticker, targets_data in results.items():\n",
    "    for target_col, models_data in targets_data.items():\n",
    "        for model_name, model_results in models_data.items():\n",
    "            if 'metrics' in model_results and model_results['metrics']: # Проверяем, что метрики существуют\n",
    "                metrics = model_results['metrics']\n",
    "                metrics['ticker'] = ticker\n",
    "                metrics['target'] = target_col\n",
    "                metrics['model'] = model_name\n",
    "                all_metrics_data.append(metrics)\n",
    "            elif 'error' in model_results: # Записываем информацию об ошибке, если она была\n",
    "                 all_metrics_data.append({\n",
    "                     'ticker': ticker,\n",
    "                     'target': target_col,\n",
    "                     'model': model_name,\n",
    "                     'mae': np.nan, 'mse': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan,\n",
    "                     'error': model_results['error']\n",
    "                 })\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics_data)\n",
    "\n",
    "# Упорядочим колонки для лучшей читаемости\n",
    "metric_cols = ['mae', 'rmse', 'r2', 'mape'] # Основные метрики\n",
    "id_cols = ['ticker', 'target', 'model']\n",
    "other_cols = [col for col in metrics_df.columns if col not in metric_cols + id_cols] # mse, error и т.д.\n",
    "metrics_df = metrics_df[id_cols + metric_cols + other_cols]\n",
    "\n",
    "# --- Отображение метрик ---\n",
    "print(\"Сводная таблица метрик по всем моделям, тикерам и таргетам:\")\n",
    "\n",
    "# Отсортируем для наглядности\n",
    "metrics_df_sorted = metrics_df.sort_values(by=['ticker', 'target', 'rmse']) # Сортируем по RMSE как основной метрике\n",
    "\n",
    "# Используем display для красивого вывода DataFrame в Jupyter\n",
    "from IPython.display import display\n",
    "display(metrics_df_sorted)\n",
    "\n",
    "# --- Найдем лучшие модели по RMSE для каждого тикера и таргета ---\n",
    "best_models = metrics_df_sorted.loc[metrics_df_sorted.groupby(['ticker', 'target'])['rmse'].idxmin()]\n",
    "\n",
    "print(\"\\nЛучшие модели по RMSE для каждого тикера и таргета:\")\n",
    "display(best_models[['ticker', 'target', 'model', 'rmse', 'mae', 'r2', 'mape']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение моделей ---\n",
    "\n",
    "# Установим стиль seaborn для графиков\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Перебираем тикеры\n",
    "for ticker in metrics_df['ticker'].unique():\n",
    "    # Фильтруем данные для текущего тикера\n",
    "    ticker_metrics = metrics_df[metrics_df['ticker'] == ticker]\n",
    "\n",
    "    # Создаем сетку графиков: одна строка, количество столбцов = количество таргетов\n",
    "    n_targets = len(ticker_metrics['target'].unique())\n",
    "    fig, axes = plt.subplots(1, n_targets, figsize=(5 * n_targets, 5), sharey=True) # Share Y-axis for better comparison if scales are similar\n",
    "    fig.suptitle(f'Сравнение моделей по RMSE для тикера: {ticker}', fontsize=16, y=1.02)\n",
    "\n",
    "    # Перебираем таргеты и строим график для каждого\n",
    "    for i, target_col in enumerate(sorted(ticker_metrics['target'].unique())): # Сортируем таргеты для порядка\n",
    "        ax = axes[i] if n_targets > 1 else axes # Handle single target case\n",
    "        target_data = ticker_metrics[ticker_metrics['target'] == target_col]\n",
    "\n",
    "        # Строим столбчатую диаграмму RMSE\n",
    "        sns.barplot(x='model', y='rmse', data=target_data, ax=ax, palette='viridis')\n",
    "        ax.set_title(f'Таргет: {target_col}')\n",
    "        ax.set_xlabel('Модель')\n",
    "        ax.set_ylabel('RMSE' if i == 0 else '') # Подпись оси Y только для первого графика\n",
    "        ax.tick_params(axis='x', rotation=45) # Поворачиваем подписи моделей для читаемости\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to prevent title overlap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение таргетов ---\n",
    "\n",
    "# Перебираем тикеры\n",
    "for ticker in metrics_df['ticker'].unique():\n",
    "    print(f\"--- Графики для тикера: {ticker} ---\")\n",
    "    ticker_metrics = metrics_df[metrics_df['ticker'] == ticker].copy() # Берем данные тикера\n",
    "\n",
    "    # Преобразуем таргет в число для сортировки (1d -> 1, 3d -> 3, ...)\n",
    "    ticker_metrics['target_days'] = ticker_metrics['target'].str.extract('(\\d+)').astype(int)\n",
    "    ticker_metrics.sort_values(by='target_days', inplace=True)\n",
    "\n",
    "    # Создаем сетку графиков: одна строка, количество столбцов = количество моделей\n",
    "    n_models = len(ticker_metrics['model'].unique())\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(5 * n_models, 5), sharey=False) # Оси Y могут сильно отличаться\n",
    "    fig.suptitle(f'Сравнение RMSE по таргетам для тикера: {ticker}', fontsize=16, y=1.02)\n",
    "\n",
    "    # Перебираем модели и строим график для каждой\n",
    "    for i, model_name in enumerate(sorted(ticker_metrics['model'].unique())):\n",
    "        ax = axes[i] if n_models > 1 else axes\n",
    "        model_data = ticker_metrics[ticker_metrics['model'] == model_name]\n",
    "\n",
    "        # Строим столбчатую диаграмму RMSE\n",
    "        sns.barplot(x='target', y='rmse', data=model_data, ax=ax, palette='magma', order=sorted(ticker_metrics['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1])))\n",
    "        ax.set_title(f'Модель: {model_name}')\n",
    "        ax.set_xlabel('Таргет')\n",
    "        ax.set_ylabel('RMSE' if i == 0 else '') # Подпись оси Y только для первого графика\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Факт vs Прогноз ---\n",
    "\n",
    "# Выберем тикер и таргет для примера\n",
    "example_ticker = 'SBER'\n",
    "example_target = 'target_7d'\n",
    "\n",
    "if example_ticker in results and example_target in results[example_ticker]:\n",
    "    # Найдем лучшую модель для этого примера\n",
    "    best_model_name = best_models[(best_models['ticker'] == example_ticker) & (best_models['target'] == example_target)]['model'].iloc[0]\n",
    "    print(f\"\\nГрафик Факт vs Прогноз для {example_ticker}, таргет {example_target}, модель: {best_model_name}\")\n",
    "\n",
    "    # Получаем реальные данные и предсказания\n",
    "    y_test_actual = split_data[example_ticker][example_target]['y_test']\n",
    "    predictions = results[example_ticker][example_target][best_model_name]['predictions']\n",
    "\n",
    "    if predictions is not None and not y_test_actual.empty:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(y_test_actual.index, y_test_actual, label='Реальные значения (Test)', color='blue', marker='.')\n",
    "        plt.plot(predictions.index, predictions, label='Предсказания модели (Test)', color='red', linestyle='--', marker='x')\n",
    "        plt.title(f'{example_ticker} - {example_target}: Реальные vs Предсказанные ({best_model_name})')\n",
    "        plt.xlabel('Дата')\n",
    "        plt.ylabel('Значение таргета')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Не удалось построить график: отсутствуют предсказания или реальные данные.\")\n",
    "else:\n",
    "    print(f\"Не найдены результаты для {example_ticker} / {example_target} для построения графика Факт vs Прогноз.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_sequences(X_data, y_data, sequence_length):\n",
    "    \"\"\"Преобразует временные ряды в последовательности для LSTM.\"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_data) - sequence_length):\n",
    "        X_seq.append(X_data.iloc[i:(i + sequence_length)].values)\n",
    "        y_seq.append(y_data.iloc[i + sequence_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def build_lstm_model(sequence_length, n_features):\n",
    "    \"\"\"Строит простую LSTM модель.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(sequence_length, n_features), return_sequences=True), # Первый слой LSTM\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'), # Второй слой LSTM\n",
    "        Dropout(0.2),\n",
    "        Dense(25, activation='relu'), # Полносвязный слой\n",
    "        Dense(1) # Выходной слой (1 нейрон для регрессии)\n",
    "    ])\n",
    "    # Используем Adam с пониженной скоростью обучения по умолчанию\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse') # Компилируем с MSE loss\n",
    "    return model\n",
    "\n",
    "print(\"Импорты и функции для LSTM добавлены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Параметры LSTM ---\n",
    "SEQUENCE_LENGTH = 20 # Длина последовательности для входа LSTM\n",
    "EPOCHS = 50          # Максимальное количество эпох\n",
    "BATCH_SIZE = 32      # Размер батча\n",
    "\n",
    "# --- Цикл обучения LSTM ---\n",
    "lstm_start_time = time.time()\n",
    "\n",
    "for ticker in split_data.keys():\n",
    "    print(f\"\\n===== LSTM Обучение для тикера: {ticker} =====\")\n",
    "    if ticker not in results:\n",
    "        results[ticker] = {} # На всякий случай, если вдруг не создалось\n",
    "\n",
    "    for target_col in split_data[ticker].keys():\n",
    "        print(f\"  --- LSTM Таргет: {target_col} ---\")\n",
    "        if target_col not in results[ticker]:\n",
    "            results[ticker][target_col] = {}\n",
    "\n",
    "        model_name = \"LSTM\"\n",
    "        start_model_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Извлекаем масштабированные данные\n",
    "            data = split_data[ticker][target_col]\n",
    "            X_train_scaled = data['X_train']\n",
    "            y_train = data['y_train']\n",
    "            X_val_scaled = data['X_val']\n",
    "            y_val = data['y_val']\n",
    "            X_test_scaled = data['X_test']\n",
    "            y_test = data['y_test']\n",
    "\n",
    "            # Создаем последовательности\n",
    "            X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, SEQUENCE_LENGTH)\n",
    "            X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, SEQUENCE_LENGTH)\n",
    "            X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, SEQUENCE_LENGTH)\n",
    "\n",
    "            # Проверяем, достаточно ли данных после создания последовательностей\n",
    "            if len(X_train_seq) == 0 or len(X_val_seq) == 0 or len(X_test_seq) == 0:\n",
    "                print(f\"    Недостаточно данных для создания последовательностей (seq_len={SEQUENCE_LENGTH}). Пропуск LSTM для {ticker}-{target_col}.\")\n",
    "                results[ticker][target_col][model_name] = {'metrics': {}, 'predictions': None, 'error': 'Insufficient data for sequences'}\n",
    "                continue\n",
    "\n",
    "            n_features = X_train_seq.shape[2] # Количество признаков\n",
    "\n",
    "            # Строим модель\n",
    "            lstm_model = build_lstm_model(SEQUENCE_LENGTH, n_features)\n",
    "            # print(lstm_model.summary()) # Можно раскомментировать для просмотра структуры модели\n",
    "\n",
    "            # Коллбэки для обучения\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "\n",
    "            # Обучение модели\n",
    "            history = lstm_model.fit(X_train_seq, y_train_seq,\n",
    "                                     epochs=EPOCHS,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     validation_data=(X_val_seq, y_val_seq),\n",
    "                                     callbacks=[early_stopping, reduce_lr],\n",
    "                                     verbose=0) # verbose=0 чтобы не выводить лог каждой эпохи\n",
    "\n",
    "            # Предсказание\n",
    "            y_pred_seq = lstm_model.predict(X_test_seq, verbose=0).flatten() # predict возвращает (n_samples, 1), flatten нужен\n",
    "\n",
    "            # Расчет метрик (используем y_test_seq, т.к. предсказания сделаны на X_test_seq)\n",
    "            metrics = calculate_metrics(y_test_seq, y_pred_seq)\n",
    "\n",
    "            # Сохраняем результаты\n",
    "            # Для сопоставления предсказаний с датами, берем индекс из y_test, начиная с SEQUENCE_LENGTH-го элемента\n",
    "            prediction_index = y_test.index[SEQUENCE_LENGTH:]\n",
    "            results[ticker][target_col][model_name] = {\n",
    "                'metrics': metrics,\n",
    "                'predictions': pd.Series(y_pred_seq, index=prediction_index)\n",
    "            }\n",
    "            print(f\"      LSTM MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R2: {metrics['r2']:.4f}, MAPE: {metrics['mape']:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Ошибка при обучении/оценке LSTM для {ticker}-{target_col}: {e}\")\n",
    "            results[ticker][target_col][model_name] = {'metrics': {}, 'predictions': None, 'error': str(e)}\n",
    "\n",
    "        end_model_time = time.time()\n",
    "        print(f\"      LSTM Время: {end_model_time - start_model_time:.2f} сек.\")\n",
    "\n",
    "lstm_end_time = time.time()\n",
    "print(f\"\\n===== LSTM Обучение завершено! Общее время: {lstm_end_time - lstm_start_time:.2f} сек. =====\")\n",
    "\n",
    "# Обновим DataFrame с метриками, включив LSTM\n",
    "all_metrics_data = []\n",
    "for ticker, targets_data in results.items():\n",
    "    for target_col, models_data in targets_data.items():\n",
    "        for model_name, model_results in models_data.items():\n",
    "            if 'metrics' in model_results and model_results['metrics']: # Проверяем, что метрики существуют\n",
    "                metrics = model_results['metrics'].copy() # Копируем, чтобы не изменить исходный словарь\n",
    "                metrics['ticker'] = ticker\n",
    "                metrics['target'] = target_col\n",
    "                metrics['model'] = model_name\n",
    "                all_metrics_data.append(metrics)\n",
    "            elif 'error' in model_results:\n",
    "                 all_metrics_data.append({\n",
    "                     'ticker': ticker, 'target': target_col, 'model': model_name,\n",
    "                     'mae': np.nan, 'mse': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan,\n",
    "                     'error': model_results['error']\n",
    "                 })\n",
    "\n",
    "metrics_df_updated = pd.DataFrame(all_metrics_data)\n",
    "# Упорядочим колонки\n",
    "metric_cols = ['mae', 'rmse', 'r2', 'mape']\n",
    "id_cols = ['ticker', 'target', 'model']\n",
    "other_cols = [col for col in metrics_df_updated.columns if col not in metric_cols + id_cols]\n",
    "metrics_df_updated = metrics_df_updated[id_cols + metric_cols + other_cols]\n",
    "\n",
    "# --- Отображение обновленных метрик ---\n",
    "print(\"\\nОбновленная сводная таблица метрик (включая LSTM):\")\n",
    "metrics_df_sorted_updated = metrics_df_updated.sort_values(by=['ticker', 'target', 'rmse'])\n",
    "display(metrics_df_sorted_updated)\n",
    "\n",
    "# --- Обновленные лучшие модели ---\n",
    "best_models_updated = metrics_df_sorted_updated.loc[metrics_df_sorted_updated.groupby(['ticker', 'target'])['rmse'].idxmin()]\n",
    "print(\"\\nОбновленные лучшие модели по RMSE для каждого тикера и таргета:\")\n",
    "display(best_models_updated[['ticker', 'target', 'model', 'rmse', 'mae', 'r2', 'mape']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение моделей (включая LSTM) ---\n",
    "\n",
    "# Перебираем тикеры\n",
    "for ticker in metrics_df_updated['ticker'].unique():\n",
    "    # Фильтруем данные для текущего тикера\n",
    "    ticker_metrics = metrics_df_updated[metrics_df_updated['ticker'] == ticker]\n",
    "\n",
    "    # Создаем сетку графиков: одна строка, количество столбцов = количество таргетов\n",
    "    targets = sorted(ticker_metrics['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1])) # Сортируем таргеты\n",
    "    n_targets = len(targets)\n",
    "    if n_targets == 0: continue # Пропускаем, если нет таргетов для тикера\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_targets, figsize=(5 * n_targets, 5), sharey=True) # Share Y-axis\n",
    "    if n_targets == 1: # Если только один таргет, axes не будет массивом\n",
    "        axes = [axes]\n",
    "    fig.suptitle(f'Сравнение моделей по RMSE для тикера: {ticker} (с LSTM)', fontsize=16, y=1.02)\n",
    "\n",
    "    # Перебираем таргеты и строим график для каждого\n",
    "    for i, target_col in enumerate(targets):\n",
    "        ax = axes[i]\n",
    "        target_data = ticker_metrics[ticker_metrics['target'] == target_col]\n",
    "\n",
    "        # Строим столбчатую диаграмму RMSE\n",
    "        sns.barplot(x='model', y='rmse', data=target_data, ax=ax, palette='viridis', order=sorted(target_data['model'].unique())) # Сортируем модели для порядка\n",
    "        ax.set_title(f'Таргет: {target_col}')\n",
    "        ax.set_xlabel('Модель')\n",
    "        ax.set_ylabel('RMSE' if i == 0 else '') # Подпись оси Y только для первого графика\n",
    "        ax.tick_params(axis='x', rotation=45) # Поворачиваем подписи моделей для читаемости\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение таргетов (включая LSTM) ---\n",
    "\n",
    "# Перебираем тикеры\n",
    "for ticker in metrics_df_updated['ticker'].unique():\n",
    "    print(f\"--- Графики для тикера: {ticker} (с LSTM) ---\")\n",
    "    ticker_metrics = metrics_df_updated[metrics_df_updated['ticker'] == ticker].copy() # Берем данные тикера\n",
    "\n",
    "    if ticker_metrics.empty: continue\n",
    "\n",
    "    # Преобразуем таргет в число для сортировки (1d -> 1, 3d -> 3, ...)\n",
    "    ticker_metrics['target_days'] = ticker_metrics['target'].str.extract('(\\d+)').astype(int)\n",
    "    ticker_metrics.sort_values(by='target_days', inplace=True)\n",
    "    sorted_targets = sorted(ticker_metrics['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1]))\n",
    "\n",
    "    # Создаем сетку графиков: одна строка, количество столбцов = количество моделей\n",
    "    models_to_plot = sorted(ticker_metrics['model'].unique())\n",
    "    n_models = len(models_to_plot)\n",
    "    if n_models == 0: continue\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(5 * n_models, 5), sharey=False) # Оси Y могут сильно отличаться\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    fig.suptitle(f'Сравнение RMSE по таргетам для тикера: {ticker} (с LSTM)', fontsize=16, y=1.02)\n",
    "\n",
    "    # Перебираем модели и строим график для каждой\n",
    "    for i, model_name in enumerate(models_to_plot):\n",
    "        ax = axes[i]\n",
    "        model_data = ticker_metrics[ticker_metrics['model'] == model_name]\n",
    "\n",
    "        # Строим столбчатую диаграмму RMSE\n",
    "        sns.barplot(x='target', y='rmse', data=model_data, ax=ax, palette='magma', order=sorted_targets)\n",
    "        ax.set_title(f'Модель: {model_name}')\n",
    "        ax.set_xlabel('Таргет')\n",
    "        ax.set_ylabel('RMSE' if i == 0 else '') # Подпись оси Y только для первого графика\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"Расчет точности предсказания знака.\"\"\"\n",
    "    # Сравниваем знаки. np.sign возвращает 1, -1 или 0.\n",
    "    # Считаем совпадение, если знаки одинаковые (включая случай, когда оба 0)\n",
    "    correct_direction = (np.sign(y_true) == np.sign(y_pred))\n",
    "    if len(correct_direction) == 0:\n",
    "        return np.nan # Невозможно посчитать для пустых данных\n",
    "    return np.mean(correct_direction) * 100 # Возвращаем в процентах\n",
    "\n",
    "# --- Пересчитаем метрики, добавив directional accuracy ---\n",
    "# Используем уже существующий словарь results\n",
    "\n",
    "for ticker in results.keys():\n",
    "    if not isinstance(results[ticker], dict): continue # Пропуск, если структура некорректна\n",
    "    for target_col in results[ticker].keys():\n",
    "         if not isinstance(results[ticker][target_col], dict): continue\n",
    "         for model_name in results[ticker][target_col].keys():\n",
    "            if not isinstance(results[ticker][target_col][model_name], dict): continue\n",
    "\n",
    "            model_results = results[ticker][target_col][model_name]\n",
    "            if 'predictions' in model_results and model_results['predictions'] is not None:\n",
    "                y_pred = model_results['predictions']\n",
    "                # Получаем y_true, соответствующий индексам y_pred\n",
    "                y_true = split_data[ticker][target_col]['y_test'][y_pred.index]\n",
    "\n",
    "                if not y_true.empty and not y_pred.empty:\n",
    "                    dir_acc = calculate_directional_accuracy(y_true.values, y_pred.values)\n",
    "                    # Добавляем новую метрику в существующий словарь\n",
    "                    results[ticker][target_col][model_name]['metrics']['dir_acc'] = dir_acc\n",
    "                else:\n",
    "                    results[ticker][target_col][model_name]['metrics']['dir_acc'] = np.nan\n",
    "            elif 'metrics' in model_results: # Если были ошибки или нет предсказаний\n",
    "                 results[ticker][target_col][model_name]['metrics']['dir_acc'] = np.nan\n",
    "\n",
    "\n",
    "# --- Снова соберем DataFrame с обновленными метриками ---\n",
    "all_metrics_data_updated = []\n",
    "for ticker, targets_data in results.items():\n",
    "    for target_col, models_data in targets_data.items():\n",
    "        for model_name, model_results in models_data.items():\n",
    "            if 'metrics' in model_results and model_results['metrics']:\n",
    "                metrics = model_results['metrics'].copy()\n",
    "                metrics['ticker'] = ticker\n",
    "                metrics['target'] = target_col\n",
    "                metrics['model'] = model_name\n",
    "                all_metrics_data_updated.append(metrics)\n",
    "            # Нет необходимости добавлять записи об ошибках снова, т.к. dir_acc будет NaN\n",
    "\n",
    "metrics_df_final = pd.DataFrame(all_metrics_data_updated)\n",
    "\n",
    "# Упорядочим колонки, добавив dir_acc\n",
    "metric_cols = ['mae', 'rmse', 'r2', 'mape', 'dir_acc'] # Добавили dir_acc\n",
    "id_cols = ['ticker', 'target', 'model']\n",
    "other_cols = [col for col in metrics_df_final.columns if col not in metric_cols + id_cols]\n",
    "metrics_df_final = metrics_df_final[id_cols + metric_cols + other_cols]\n",
    "\n",
    "# --- Отображение обновленных метрик ---\n",
    "print(\"Финальная таблица метрик (с точностью угадывания знака, %):\")\n",
    "metrics_df_final_sorted = metrics_df_final.sort_values(by=['ticker', 'target', 'dir_acc'], ascending=[True, True, False]) # Сортируем по dir_acc по убыванию\n",
    "display(metrics_df_final_sorted)\n",
    "\n",
    "# --- Лучшие модели по точности угадывания знака ---\n",
    "best_dir_acc_models = metrics_df_final_sorted.loc[metrics_df_final_sorted.groupby(['ticker', 'target'])['dir_acc'].idxmax()]\n",
    "print(\"\\nЛучшие модели по точности угадывания знака (%) для каждого тикера и таргета:\")\n",
    "display(best_dir_acc_models[['ticker', 'target', 'model', 'dir_acc', 'r2', 'rmse']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Параметры ---\n",
    "COMBINED_DATA_FILENAME = 'combined_data.csv' # Уточните, если имя другое\n",
    "combined_file_path = os.path.join(data_path, COMBINED_DATA_FILENAME)\n",
    "\n",
    "# --- Загрузка объединенного датасета ---\n",
    "combined_df = None\n",
    "if os.path.exists(combined_file_path):\n",
    "    try:\n",
    "        combined_df = pd.read_csv(combined_file_path, parse_dates=['DATE'], index_col='DATE')\n",
    "        combined_df = combined_df.sort_index() # Сортируем по дате\n",
    "        print(f\"Загружен объединенный датасет: {combined_df.shape}\")\n",
    "        print(f\"Уникальные тикеры в датасете: {combined_df['SECID'].unique()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке объединенного датасета '{combined_file_path}': {e}\")\n",
    "else:\n",
    "    print(f\"Объединенный файл не найден: {combined_file_path}\")\n",
    "    print(\"Пожалуйста, убедитесь, что файл существует и имя указано верно.\")\n",
    "\n",
    "# --- Подготовка признаков и целей (если датасет загружен) ---\n",
    "if combined_df is not None:\n",
    "    # Целевые колонки\n",
    "    combined_target_columns = [col for col in combined_df.columns if 'target' in col]\n",
    "    print(f\"\\nЦелевые колонки: {combined_target_columns}\")\n",
    "\n",
    "    # Колонки признаков (все числовые + SECID, кроме целей)\n",
    "    combined_exclude_cols = combined_target_columns\n",
    "    # Сначала все числовые\n",
    "    combined_feature_columns_numeric = [col for col in combined_df.select_dtypes(include=[np.number]).columns if col not in combined_exclude_cols]\n",
    "    # Добавляем SECID\n",
    "    combined_feature_columns = combined_feature_columns_numeric + ['SECID']\n",
    "    categorical_features = ['SECID'] # Список категориальных признаков\n",
    "\n",
    "    print(f\"Колонки признаков ({len(combined_feature_columns)}): {combined_feature_columns[:5]}...{combined_feature_columns[-5:]}\")\n",
    "    print(f\"Категориальные признаки: {categorical_features}\")\n",
    "\n",
    "    # Преобразуем категориальный признак для LightGBM\n",
    "    combined_df['SECID'] = combined_df['SECID'].astype('category')\n",
    "\n",
    "    # Проверим наличие пропусков в таргетах и удалим строки при необходимости\n",
    "    initial_rows_combined = len(combined_df)\n",
    "    combined_df.dropna(subset=combined_target_columns, inplace=True)\n",
    "    removed_rows_combined = initial_rows_combined - len(combined_df)\n",
    "    if removed_rows_combined > 0:\n",
    "        print(f\"\\nУдалено {removed_rows_combined} строк с пропусками в target из объединенного датасета.\")\n",
    "\n",
    "    # Разделение данных\n",
    "    X_combined = combined_df[combined_feature_columns]\n",
    "    y_combined = combined_df[combined_target_columns]\n",
    "\n",
    "    n_combined = len(combined_df)\n",
    "    train_end_idx_comb = int(n_combined * TRAIN_SIZE)\n",
    "    validation_end_idx_comb = int(n_combined * (TRAIN_SIZE + VALIDATION_SIZE))\n",
    "\n",
    "    X_train_comb = X_combined.iloc[:train_end_idx_comb]\n",
    "    X_val_comb = X_combined.iloc[train_end_idx_comb:validation_end_idx_comb]\n",
    "    X_test_comb = X_combined.iloc[validation_end_idx_comb:]\n",
    "\n",
    "    y_train_comb = y_combined.iloc[:train_end_idx_comb]\n",
    "    y_val_comb = y_combined.iloc[train_end_idx_comb:validation_end_idx_comb]\n",
    "    y_test_comb = y_combined.iloc[validation_end_idx_comb:]\n",
    "\n",
    "    print(f\"\\nРазмеры выборок для объединенного датасета: Train={len(X_train_comb)}, Validation={len(X_val_comb)}, Test={len(X_test_comb)}\")\n",
    "\n",
    "    if len(X_train_comb) == 0 or len(X_val_comb) == 0 or len(X_test_comb) == 0:\n",
    "        print(f\"  Недостаточно данных для разделения объединенного датасета.\")\n",
    "        combined_df = None # Сбрасываем df, чтобы не продолжать\n",
    "\n",
    "else:\n",
    "    print(\"Обучение на объединенном датасете невозможно без загрузки данных.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Модели для объединенного датасета ---\n",
    "models_combined = {\n",
    "    # LightGBM должен сам обработать тип 'category' для SECID\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=42, n_estimators=100, learning_rate=0.1),\n",
    "    # Для CatBoost явно указываем категориальный признак\n",
    "    \"CatBoost\": cb.CatBoostRegressor(random_state=42, iterations=100, verbose=0, early_stopping_rounds=10,\n",
    "                                     cat_features=categorical_features) # Передаем список кат. признаков\n",
    "}\n",
    "\n",
    "# --- Словарь для хранения результатов объединенного датасета ---\n",
    "results_combined = {} # {target: {model_name: {'metrics': {...}, 'predictions': ...}}}\n",
    "\n",
    "# --- Цикл обучения на объединенном датасете ---\n",
    "if combined_df is not None: # Продолжаем, только если данные были успешно загружены и разделены\n",
    "    combined_training_start_time = time.time()\n",
    "    print(\"\\n===== Обучение на ОБЪЕДИНЕННОМ датасете =====\")\n",
    "\n",
    "    for target_col in combined_target_columns:\n",
    "        print(f\"  --- Таргет: {target_col} ---\")\n",
    "        results_combined[target_col] = {}\n",
    "\n",
    "        # Извлекаем y для текущего таргета\n",
    "        y_train_target = y_train_comb[target_col]\n",
    "        y_val_target = y_val_comb[target_col]\n",
    "        y_test_target = y_test_comb[target_col]\n",
    "\n",
    "        # Проверка на пустые y\n",
    "        if y_val_target.empty or y_test_target.empty:\n",
    "             print(f\"    Пропуск таргета {target_col} из-за пустых y_val или y_test.\")\n",
    "             continue\n",
    "\n",
    "        for model_name, model in models_combined.items():\n",
    "            print(f\"    Модель: {model_name}\")\n",
    "            start_model_time = time.time()\n",
    "\n",
    "            # Используем X_train_comb, X_val_comb, X_test_comb\n",
    "            # Масштабирование не применялось, пропуски не заполнялись (модели должны справиться)\n",
    "            X_train_fit = X_train_comb\n",
    "            X_val_fit = X_val_comb\n",
    "            X_test_predict = X_test_comb\n",
    "\n",
    "            try:\n",
    "                # Обучение модели\n",
    "                if model_name == \"LightGBM\":\n",
    "                    callbacks = [lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "                    # Убедимся, что категориальный признак имеет правильный тип\n",
    "                    X_train_fit_lgb = X_train_fit.copy()\n",
    "                    X_val_fit_lgb = X_val_fit.copy()\n",
    "                    X_test_predict_lgb = X_test_predict.copy()\n",
    "                    for col in categorical_features:\n",
    "                         if col in X_train_fit_lgb.columns:\n",
    "                              X_train_fit_lgb[col] = X_train_fit_lgb[col].astype('category')\n",
    "                              X_val_fit_lgb[col] = X_val_fit_lgb[col].astype('category')\n",
    "                              X_test_predict_lgb[col] = X_test_predict_lgb[col].astype('category')\n",
    "\n",
    "                    model.fit(X_train_fit_lgb, y_train_target,\n",
    "                              eval_set=[(X_val_fit_lgb, y_val_target)],\n",
    "                              callbacks=callbacks)\n",
    "                    # Предсказание делаем на данных с правильным типом категории\n",
    "                    y_pred = model.predict(X_test_predict_lgb)\n",
    "\n",
    "                elif model_name == \"CatBoost\":\n",
    "                     # cat_features уже указан в конструкторе\n",
    "                     model.fit(X_train_fit, y_train_target,\n",
    "                               eval_set=[(X_val_fit, y_val_target)],\n",
    "                               verbose=0)\n",
    "                     y_pred = model.predict(X_test_predict)\n",
    "\n",
    "                # Расчет метрик\n",
    "                metrics = calculate_metrics(y_test_target, y_pred)\n",
    "                # Добавляем точность угадывания знака\n",
    "                metrics['dir_acc'] = calculate_directional_accuracy(y_test_target.values, y_pred)\n",
    "\n",
    "                results_combined[target_col][model_name] = {\n",
    "                    'metrics': metrics,\n",
    "                    'predictions': pd.Series(y_pred, index=y_test_target.index)\n",
    "                }\n",
    "                print(f\"      MAE: {metrics['mae']:.4f}, RMSE: {metrics['rmse']:.4f}, R2: {metrics['r2']:.4f}, MAPE: {metrics['mape']:.4f}, DirAcc: {metrics['dir_acc']:.2f}%\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Ошибка при обучении/оценке модели {model_name} для таргета {target_col}: {e}\")\n",
    "                results_combined[target_col][model_name] = {'metrics': {}, 'predictions': None, 'error': str(e)}\n",
    "\n",
    "            end_model_time = time.time()\n",
    "            print(f\"      Время: {end_model_time - start_model_time:.2f} сек.\")\n",
    "\n",
    "    combined_training_end_time = time.time()\n",
    "    print(f\"\\n===== Обучение на объединенном датасете завершено! Общее время: {combined_training_end_time - combined_training_start_time:.2f} сек. =====\")\n",
    "\n",
    "    # --- Сбор метрик в DataFrame ---\n",
    "    combined_metrics_data = []\n",
    "    for target_col, models_data in results_combined.items():\n",
    "        for model_name, model_results in models_data.items():\n",
    "            if 'metrics' in model_results and model_results['metrics']:\n",
    "                metrics = model_results['metrics'].copy()\n",
    "                metrics['target'] = target_col\n",
    "                metrics['model'] = model_name\n",
    "                combined_metrics_data.append(metrics)\n",
    "\n",
    "    metrics_df_combined = pd.DataFrame(combined_metrics_data)\n",
    "\n",
    "    # Упорядочим колонки\n",
    "    metric_cols = ['mae', 'rmse', 'r2', 'mape', 'dir_acc']\n",
    "    id_cols = ['target', 'model']\n",
    "    other_cols = [col for col in metrics_df_combined.columns if col not in metric_cols + id_cols]\n",
    "    metrics_df_combined = metrics_df_combined[id_cols + metric_cols + other_cols]\n",
    "\n",
    "    # --- Отображение метрик ---\n",
    "    print(\"\\nСводная таблица метрик для объединенного датасета:\")\n",
    "    metrics_df_combined_sorted = metrics_df_combined.sort_values(by=['target', 'dir_acc'], ascending=[True, False])\n",
    "    display(metrics_df_combined_sorted)\n",
    "\n",
    "    # --- Лучшие модели по точности угадывания знака ---\n",
    "    best_dir_acc_models_combined = metrics_df_combined_sorted.loc[metrics_df_combined_sorted.groupby(['target'])['dir_acc'].idxmax()]\n",
    "    print(\"\\nЛучшие модели по точности угадывания знака (%) для каждого таргета (объединенный датасет):\")\n",
    "    display(best_dir_acc_models_combined[['target', 'model', 'dir_acc', 'r2', 'rmse']])\n",
    "\n",
    "else:\n",
    "    print(\"\\nОбучение на объединенном датасете не выполнено из-за отсутствия данных.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Подготовка данных для сравнения ---\n",
    "\n",
    "# Метрики из индивидуального обучения (только LGBM и CatBoost)\n",
    "metrics_individual = metrics_df_final[metrics_df_final['model'].isin(['LightGBM', 'CatBoost'])].copy()\n",
    "\n",
    "# Усредняем метрики по тикерам для каждого таргета и модели\n",
    "metrics_individual_avg = metrics_individual.groupby(['target', 'model'])[['rmse', 'dir_acc']].mean().reset_index()\n",
    "metrics_individual_avg['experiment'] = 'Individual (Avg)'\n",
    "\n",
    "# Метрики из объединенного обучения\n",
    "metrics_combined_comp = metrics_df_combined[['target', 'model', 'rmse', 'dir_acc']].copy()\n",
    "metrics_combined_comp['experiment'] = 'Combined'\n",
    "\n",
    "# Объединяем\n",
    "comparison_df = pd.concat([metrics_individual_avg, metrics_combined_comp], ignore_index=True)\n",
    "\n",
    "# Сортируем для наглядности\n",
    "comparison_df['target_days'] = comparison_df['target'].str.extract('(\\d+)').astype(int)\n",
    "comparison_df.sort_values(by=['target_days', 'model', 'experiment'], inplace=True)\n",
    "\n",
    "print(\"Данные для сравнения:\")\n",
    "display(comparison_df[['experiment', 'target', 'model', 'rmse', 'dir_acc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение RMSE ---\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(x='target', y='rmse', hue='experiment', data=comparison_df, palette='coolwarm',\n",
    "            order=sorted(comparison_df['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1]))) # Сортировка таргетов\n",
    "\n",
    "plt.title('Сравнение RMSE: Индивидуальное (среднее) vs Объединенное обучение', fontsize=16)\n",
    "plt.xlabel('Таргет')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Тип эксперимента')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Отдельные графики по моделям для лучшей читаемости\n",
    "for model_name in ['LightGBM', 'CatBoost']:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    model_data = comparison_df[comparison_df['model'] == model_name]\n",
    "    sns.barplot(x='target', y='rmse', hue='experiment', data=model_data, palette='coolwarm',\n",
    "                order=sorted(model_data['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1])))\n",
    "    plt.title(f'Сравнение RMSE для модели: {model_name}', fontsize=14)\n",
    "    plt.xlabel('Таргет')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Тип эксперимента')\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Визуализация: Сравнение Directional Accuracy ---\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(x='target', y='dir_acc', hue='experiment', data=comparison_df, palette='viridis',\n",
    "            order=sorted(comparison_df['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1]))) # Сортировка таргетов\n",
    "\n",
    "plt.title('Сравнение Точности Угадывания Знака (%): Индивидуальное (среднее) vs Объединенное', fontsize=16)\n",
    "plt.xlabel('Таргет')\n",
    "plt.ylabel('Точность угадывания знака (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Тип эксперимента')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.ylim(bottom=min(40, comparison_df['dir_acc'].min() - 2 )) # Установим нижнюю границу оси Y для наглядности\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Отдельные графики по моделям\n",
    "for model_name in ['LightGBM', 'CatBoost']:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    model_data = comparison_df[comparison_df['model'] == model_name]\n",
    "    sns.barplot(x='target', y='dir_acc', hue='experiment', data=model_data, palette='viridis',\n",
    "                 order=sorted(model_data['target'].unique(), key=lambda x: int(x.split('d')[0].split('_')[-1])))\n",
    "    plt.title(f'Сравнение Точности Угадывания Знака для модели: {model_name}', fontsize=14)\n",
    "    plt.xlabel('Таргет')\n",
    "    plt.ylabel('Точность угадывания знака (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Тип эксперимента')\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.ylim(bottom=min(40, model_data['dir_acc'].min() - 2 ))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Анализ корреляций ---\n",
    "\n",
    "# Выберем тикер и таргет для анализа\n",
    "analyze_ticker = 'SBER'\n",
    "analyze_target = 'target_7d'\n",
    "top_n_corr = 15 # Количество признаков для вывода\n",
    "\n",
    "if analyze_ticker in split_data and analyze_target in split_data[analyze_ticker]:\n",
    "    print(f\"--- Анализ корреляций для {analyze_ticker}, таргет: {analyze_target} ---\")\n",
    "\n",
    "    # Используем оригинальные данные трейна (с импутацией, но до масштабирования)\n",
    "    X_train_analyze = split_data[analyze_ticker][analyze_target]['X_train_orig']\n",
    "    y_train_analyze = split_data[analyze_ticker][analyze_target]['y_train']\n",
    "\n",
    "    # Объединим признаки и таргет для расчета корреляции\n",
    "    train_data_analyze = pd.concat([X_train_analyze, y_train_analyze], axis=1)\n",
    "\n",
    "    # Рассчитаем матрицу корреляций\n",
    "    correlation_matrix = train_data_analyze.corr()\n",
    "\n",
    "    # Корреляция всех признаков с целевой переменной\n",
    "    corr_with_target = correlation_matrix[analyze_target].sort_values(ascending=False)\n",
    "\n",
    "    print(f\"\\nТоп-{top_n_corr} признаков по абсолютной корреляции с {analyze_target}:\")\n",
    "    # Берем топ по модулю, исключая сам таргет (corr=1)\n",
    "    top_correlated_features = corr_with_target.drop(analyze_target).abs().nlargest(top_n_corr)\n",
    "    display(corr_with_target.loc[top_correlated_features.index])\n",
    "\n",
    "    # Визуализация части матрицы корреляций (Топ N признаков + таргет)\n",
    "    cols_to_plot = top_correlated_features.index.tolist() + [analyze_target]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix.loc[cols_to_plot, cols_to_plot],\n",
    "                annot=False, # Аннотации могут сделать график нечитаемым при большом N\n",
    "                cmap='coolwarm',\n",
    "                linewidths=0.5)\n",
    "    plt.title(f'Матрица корреляций для топ-{top_n_corr} признаков и таргета ({analyze_ticker} / {analyze_target})')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Не найдены данные для анализа корреляций: {analyze_ticker} / {analyze_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Важность признаков из моделей ---\n",
    "top_n_features = 20 # Количество признаков для отображения на графиках\n",
    "feature_importances = {} # Словарь для хранения важности\n",
    "\n",
    "if analyze_ticker in split_data and analyze_target in split_data[analyze_ticker]:\n",
    "    print(f\"\\n--- Анализ важности признаков из моделей для {analyze_ticker}, таргет: {analyze_target} ---\")\n",
    "\n",
    "    # Данные для обучения (оригинальные импутированные)\n",
    "    X_train_fit = split_data[analyze_ticker][analyze_target]['X_train_orig']\n",
    "    y_train_fit = split_data[analyze_ticker][analyze_target]['y_train']\n",
    "    X_val_fit = split_data[analyze_ticker][analyze_target]['X_val_orig']\n",
    "    y_val_fit = split_data[analyze_ticker][analyze_target]['y_val']\n",
    "\n",
    "    # Модели для анализа важности\n",
    "    models_for_importance = {\n",
    "        \"XGBoost\": xgb.XGBRegressor(random_state=42, n_estimators=100, early_stopping_rounds=10),\n",
    "        \"LightGBM\": lgb.LGBMRegressor(random_state=42, n_estimators=100, learning_rate=0.1),\n",
    "        \"CatBoost\": cb.CatBoostRegressor(random_state=42, iterations=100, verbose=0, early_stopping_rounds=10)\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(len(models_for_importance), 1, figsize=(12, 6 * len(models_for_importance)))\n",
    "    if len(models_for_importance) == 1: axes = [axes] # Handle single model case\n",
    "    fig.suptitle(f'Важность признаков ({analyze_ticker} / {analyze_target})', fontsize=16, y=1.0)\n",
    "\n",
    "\n",
    "    for i, (model_name, model) in enumerate(models_for_importance.items()):\n",
    "        print(f\"  Обучение {model_name} для получения важности...\")\n",
    "        try:\n",
    "            # Обучение (как в предыдущем цикле)\n",
    "            if model_name == \"XGBoost\":\n",
    "                model.fit(X_train_fit, y_train_fit, eval_set=[(X_val_fit, y_val_fit)], verbose=False)\n",
    "                importances = model.feature_importances_\n",
    "            elif model_name == \"LightGBM\":\n",
    "                callbacks = [lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "                model.fit(X_train_fit, y_train_fit, eval_set=[(X_val_fit, y_val_fit)], callbacks=callbacks)\n",
    "                importances = model.feature_importances_\n",
    "            elif model_name == \"CatBoost\":\n",
    "                 model.fit(X_train_fit, y_train_fit, eval_set=[(X_val_fit, y_val_fit)], verbose=0)\n",
    "                 importances = model.get_feature_importance()\n",
    "\n",
    "            # Сохранение и визуализация\n",
    "            imp_df = pd.DataFrame({'feature': X_train_fit.columns, 'importance': importances})\n",
    "            imp_df = imp_df.sort_values(by='importance', ascending=False).head(top_n_features)\n",
    "            feature_importances[model_name] = imp_df\n",
    "\n",
    "            # График\n",
    "            ax = axes[i]\n",
    "            sns.barplot(x='importance', y='feature', data=imp_df, ax=ax, palette='rocket')\n",
    "            ax.set_title(f'Топ-{top_n_features} признаков для {model_name}')\n",
    "            ax.set_xlabel('Важность')\n",
    "            ax.set_ylabel('Признак')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    Ошибка при получении важности для {model_name}: {e}\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.show()\n",
    "\n",
    "    # Сравним топ признаков между моделями\n",
    "    if feature_importances:\n",
    "        print(\"\\nТоп-5 признаков по моделям:\")\n",
    "        comparison_list = []\n",
    "        for model_name, imp_df in feature_importances.items():\n",
    "             comparison_list.append(pd.Series(imp_df['feature'].values[:5], name=model_name))\n",
    "        if comparison_list:\n",
    "             comparison_df = pd.concat(comparison_list, axis=1)\n",
    "             display(comparison_df)\n",
    "\n",
    "else:\n",
    "    print(f\"Не найдены данные для анализа важности: {analyze_ticker} / {analyze_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_base_features_template = [\n",
    "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', \n",
    "    'RSI', 'MACD_Hist', 'Bear_Power', 'ATR', 'EMA_10', 'EMA_50', 'EMA_200', 'RTSI', 'EMV', 'ADX',\n",
    "    'MOEXCN', 'MOEXIT', 'MOEXRE', 'MOEXEU', 'MOEXFN', 'MOEXINN', 'MOEXMM', 'MOEXOG', 'MOEXTL', 'MOEXTN', 'MOEXCH',\n",
    "    'Revenue_y', 'NetProfit_y', 'ROE_y', 'Assets_q', 'NetProfit_q', 'PB_q',\n",
    "    'BRENT_CLOSE', 'KEY_RATE', 'USD_RUB',\n",
    "    'PE_y', 'PB_y'\n",
    "]\n",
    "\n",
    "\n",
    "    # 2. Определение новостных и блоговых признаков (только для тикера, без WeightedIndices)\n",
    "    current_news_features_specific = [\n",
    "        f'{ticker}_news_score', \n",
    "        f'{ticker}_news_score_roll_avg_5',\n",
    "        f'{ticker}_news_score_roll_avg_30',\n",
    "        'WeightedIndices_news_score'\n",
    "    ]\n",
    "    current_blog_features_specific = [\n",
    "        f'{ticker}_blog_score',\n",
    "        f'{ticker}_blog_score_roll_avg_5',\n",
    "        f'{ticker}_blog_score_roll_avg_30',\n",
    "        'WeightedIndices_blog_score'\n",
    "    ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
