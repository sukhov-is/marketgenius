{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Предварительная обработка текста без удаления стоп-слов.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^а-яА-Яa-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Загрузка модели RuBERT и токенизатора\n",
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Определяем устройство для вычислений\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def embed_text(texts):\n",
    "    \"\"\"Создает эмбеддинги для списка текстов на GPU.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        model_output = model(**encoded_input)\n",
    "        embeddings = model_output.last_hidden_state[:, 0, :].cpu()  # Перенос на CPU для дальнейшей работы\n",
    "        return embeddings.numpy()\n",
    "\n",
    "\n",
    "def find_duplicates_with_rubert(df, window_days=2, similarity_threshold=0.8):\n",
    "    df = df.copy()\n",
    "    df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "    # Создание эмбеддингов для всех текстов\n",
    "    embeddings = embed_text(df['processed_text'].tolist())\n",
    "    \n",
    "    duplicate_groups = defaultdict(set)\n",
    "    processed_indices = set()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        current_idx = df.index[i]\n",
    "        if current_idx in processed_indices:\n",
    "            continue\n",
    "\n",
    "        current_date = df.iloc[i]['datetime']\n",
    "        date_min = current_date - timedelta(days=window_days)\n",
    "        date_max = current_date + timedelta(days=window_days)\n",
    "\n",
    "        mask_window = (\n",
    "            (df['datetime'] >= date_min) &\n",
    "            (df['datetime'] <= date_max) &\n",
    "            ~df.index.isin(processed_indices)\n",
    "        )\n",
    "        window_indices = df[mask_window].index\n",
    "\n",
    "        if len(window_indices) > 1:\n",
    "            window_embeddings = embeddings[window_indices]\n",
    "\n",
    "            emb1 = torch.tensor([embeddings[i]])\n",
    "            emb2 = torch.tensor(window_embeddings)\n",
    "\n",
    "            similarities = F.cosine_similarity(emb1, emb2).numpy()\n",
    "\n",
    "            similar_indices = np.where(similarities > similarity_threshold)[0]\n",
    "            if len(similar_indices) > 1:\n",
    "                similar_indices_full = window_indices[similar_indices]\n",
    "                earliest_idx = df.loc[similar_indices_full, 'datetime'].idxmin()\n",
    "                duplicate_groups[earliest_idx].update(\n",
    "                    idx for idx in similar_indices_full if idx != earliest_idx\n",
    "                )\n",
    "                processed_indices.update(similar_indices_full)\n",
    "\n",
    "    all_duplicates = set(idx for d in duplicate_groups.values() for idx in d)\n",
    "    df_cleaned = df.drop(index=list(all_duplicates))\n",
    "    df_cleaned.drop(['datetime', 'processed_text'], axis=1, inplace=True)\n",
    "\n",
    "    logging.info(f\"Найдено {len(all_duplicates)} дубликатов в {len(duplicate_groups)} группах\")\n",
    "    logging.info(f\"Осталось {len(df_cleaned)} уникальных новостей\")\n",
    "\n",
    "    return df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Должно вернуть True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Версия CUDA, совместимая с PyTorch\n",
    "print(torch.cuda.is_available())  # Проверка, доступен ли GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(1000, 1000).cuda()\n",
    "y = torch.randn(1000, 1000).cuda()\n",
    "z = torch.matmul(x, y)\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
